{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "from torchvision.transforms.functional import normalize as F_normalize\n",
    "from torch.nn.functional import interpolate as F_upsample\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import numpy as np\n",
    "import OpenEXR, Imath\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "num_classes=7 #(6+1 for background)\n",
    "dataset_size=1270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_exr(filename):\n",
    "    \"\"\"Load an EXR file and return as a NumPy array.\"\"\"\n",
    "    file = OpenEXR.InputFile(filename)\n",
    "    dw = file.header()['dataWindow']\n",
    "    size = (dw.max.x - dw.min.x + 1, dw.max.y - dw.min.y + 1)\n",
    "\n",
    "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "    channels = ['R', 'G', 'B']\n",
    "\n",
    "    rgb = [np.frombuffer(file.channel(c, pt), dtype=np.float32) for c in channels]\n",
    "    rgb = [np.reshape(c, (size[1], size[0])) for c in rgb]\n",
    "    image = np.stack(rgb, axis=-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "class HDRDataset(Dataset):\n",
    "    def __init__(self, png_dir,exr_dir,txt_dir):\n",
    "\n",
    "        self.png_dir = png_dir\n",
    "        self.exr_dir = exr_dir\n",
    "        self.txt_dir = txt_dir\n",
    "        self.filenames = [os.path.splitext(f)[0] for f in os.listdir(png_dir) if f.endswith('.png')]\n",
    "\n",
    "        self.labels = []\n",
    "        self.bboxes = []\n",
    "\n",
    "        for filename in self.filenames:\n",
    "            txt_filename = filename + '.txt'\n",
    "            txt_path = os.path.join(txt_dir, txt_filename)\n",
    "            with open(txt_path, 'r') as file:\n",
    "                data = file.readlines()\n",
    "                cls, x, y, w, h = map(float, data[0].split())\n",
    "                self.classes.append(int(cls))\n",
    "                self.bboxes.append([x, y, w, h])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        png_path = os.path.join(self.png_dir, self.filenames[idx]+'.png')\n",
    "        exr_path = os.path.join(self.exr_dir, self.filenames[idx]+'.exr')\n",
    "        \n",
    "        exr_image = load_exr(exr_path)\n",
    "    \n",
    "        png_image = Image.open(png_path)\n",
    "        png_image = np.array(png_image)\n",
    "\n",
    "        label = self.classes[idx]\n",
    "        bbox = self.bboxes[idx]\n",
    "\n",
    "        # Convert image and bbox to tensor\n",
    "        png_image = torch.tensor(png_image, dtype=torch.float32).permute(2, 0, 1)  # Channel first format\n",
    "        bbox = torch.tensor(bbox, dtype=torch.float32)\n",
    "\n",
    "        return exr_image,png_image, label, bbox\n",
    "\n",
    "\n",
    "train_data = HDRDataset('train/png','train/exr','train/txt')\n",
    "test_data = HDRDataset('test/png','test/exr','test/txt')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientAttention(nn.Module):\n",
    "    def __init__(self, val_channels=3, key_channels=4, in_channels=0):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels if in_channels else val_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.val_channels = val_channels\n",
    "\n",
    "        self.keys = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
    "        self.values = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
    "        self.queries = nn.Conv2d(self.in_channels, self.key_channels, 1)\n",
    "        self.reprojection = nn.Conv2d(self.key_channels, self.val_channels, 1)\n",
    "\n",
    "    def forward(self, value_, input_=None):\n",
    "        n, c, h, w = value_.size()\n",
    "        values = self.values(value_).reshape((n, self.key_channels, h * w))\n",
    "        keys = self.keys(value_).reshape((n, self.key_channels, h * w))\n",
    "        \n",
    "        if input_ is not None:\n",
    "            queries = self.queries(input_)\n",
    "            \n",
    "            # maxpool the query if it is larger than the value \n",
    "            _, _, h_i, w_i = input_.size()\n",
    "            if w_i > w or h_i > h:\n",
    "                queries = F.max_pool2d(queries, (h_i//h, w_i//w))\n",
    "            \n",
    "            queries = queries.reshape(n, self.key_channels, h * w)\n",
    "        else:\n",
    "            queries = self.queries(value_).reshape(n, self.key_channels, h * w)\n",
    "\n",
    "        key = F.softmax(keys, dim=2)\n",
    "        query = F.softmax(queries, dim=1)\n",
    "        \n",
    "        context = key @ values.transpose(1, 2)\n",
    "        attention = (\n",
    "            context.transpose(1, 2) @ query\n",
    "        ).reshape(n, self.key_channels, h, w)\n",
    "\n",
    "        reprojected_value = self.reprojection(attention)\n",
    "        attention = reprojected_value + value_\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGeneratorBilinear(nn.Module):\n",
    "    def __init__(self, opt, norm_layer):\n",
    "        super(UnetGeneratorBilinear, self).__init__()\n",
    "\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        \n",
    "        self.normalize = True\n",
    "        self.self_attention = True\n",
    "        self.use_avgpool = True\n",
    "        self.skip = 0.8\n",
    "        self.use_tanh = True\n",
    "        # if self.use_tanh:\n",
    "        #     if opt.hardtanh:\n",
    "        self.final_tanh = nn.Hardtanh() \n",
    "            # else:\n",
    "            #     self.final_tanh = nn.Tanh() \n",
    "\n",
    "        p = 1\n",
    "        if self.self_attention:\n",
    "            self.conv1_1 = nn.Conv2d(6, 32, 3, padding=p)\n",
    "            self.attention_in = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
    "            self.attention_out = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
    "            self.attention_1 = EfficientAttention(val_channels=32, key_channels=4, in_channels=3)\n",
    "            self.attention_2 = EfficientAttention(val_channels=64, key_channels=4, in_channels=3)\n",
    "            self.attention_3 = EfficientAttention(val_channels=128, key_channels=8, in_channels=3)\n",
    "            self.attention_4 = EfficientAttention(val_channels=512, key_channels=16, in_channels=3)\n",
    "        else:\n",
    "            self.conv1_1 = nn.Conv2d(3, 32, 3, padding=p)\n",
    "\n",
    "        self.LReLU1_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn1_1 = norm_layer(32)\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
    "        self.LReLU1_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn1_2 = norm_layer(32)\n",
    "        self.max_pool1 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, 3, padding=p)\n",
    "        self.LReLU2_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn2_1 = norm_layer(64)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
    "        self.LReLU2_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn2_2 = norm_layer(64)\n",
    "        self.max_pool2 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(64, 128, 3, padding=p)\n",
    "        self.LReLU3_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn3_1 = norm_layer(128)\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
    "        self.LReLU3_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn3_2 = norm_layer(128)\n",
    "        self.max_pool3 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4_11 = nn.Conv2d(128, 128, 1, padding=p*0)\n",
    "        self.LReLU4_11 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_11 = norm_layer(128)\n",
    "        self.conv4_12 = nn.Conv2d(128, 128, 3, padding=p*1)\n",
    "        self.LReLU4_12 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_12 = norm_layer(128)\n",
    "        self.conv4_13 = nn.Conv2d(128, 128, 5, padding=p*2)\n",
    "        self.LReLU4_13 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_13 = norm_layer(128)\n",
    "        self.conv4_14 = nn.Conv2d(128, 128, 7, padding=p*3)\n",
    "        self.LReLU4_14 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_14 = norm_layer(128)\n",
    "        self.conv4_2 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.LReLU4_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_2 = norm_layer(256)\n",
    "        \n",
    "        \n",
    "        # Uncomment this block for further downsampling\n",
    "        '''\n",
    "        self.max_pool4 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(256, 512, 3, padding=p)\n",
    "        self.LReLU5_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn5_1 = norm_layer(512)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=p)\n",
    "        self.LReLU5_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn5_2 = norm_layer(512)\n",
    "\n",
    "        \n",
    "        self.deconv5 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.conv6_1 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.LReLU6_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn6_1 = norm_layer(256)\n",
    "        self.conv6_2 = nn.Conv2d(256, 256, 3, padding=p)\n",
    "        self.LReLU6_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn6_2 = norm_layer(256)\n",
    "        '''\n",
    "\n",
    "        self.deconv6 = nn.Conv2d(256, 128, 3, padding=p)\n",
    "        self.conv7_1 = nn.Conv2d(256, 128, 3, padding=p)\n",
    "        self.LReLU7_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn7_1 = norm_layer(128)\n",
    "        self.conv7_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
    "        self.LReLU7_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn7_2 = norm_layer(128)\n",
    "\n",
    "        self.deconv7 = nn.Conv2d(128, 64, 3, padding=p)\n",
    "        self.conv8_1 = nn.Conv2d(128, 64, 3, padding=p)\n",
    "        self.LReLU8_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn8_1 = norm_layer(64)\n",
    "        self.conv8_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
    "        self.LReLU8_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn8_2 = norm_layer(64)\n",
    "\n",
    "        self.deconv8 = nn.Conv2d(64, 32, 3, padding=p)\n",
    "        self.conv9_1 = nn.Conv2d(64, 32, 3, padding=p)\n",
    "        self.LReLU9_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn9_1 = norm_layer(32)\n",
    "        self.conv9_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
    "        self.LReLU9_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(32, 3, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.self_attention:\n",
    "            attended_inp = self.attention_in(input)\n",
    "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(torch.cat([input, attended_inp], dim=1))))\n",
    "        else:\n",
    "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(input)))\n",
    "        conv1 = self.bn1_2(self.LReLU1_2(self.conv1_2(x)))\n",
    "        x = self.max_pool1(conv1)\n",
    "\n",
    "        x = self.bn2_1(self.LReLU2_1(self.conv2_1(x)))\n",
    "        conv2 = self.bn2_2(self.LReLU2_2(self.conv2_2(x)))\n",
    "        x = self.max_pool2(conv2)\n",
    "\n",
    "        x = self.bn3_1(self.LReLU3_1(self.conv3_1(x)))\n",
    "        conv3 = self.bn3_2(self.LReLU3_2(self.conv3_2(x)))\n",
    "        x = self.max_pool3(conv3)\n",
    "\n",
    "        ########## Starts: Bottom of the U-NET ##########\n",
    "        x_1 = self.bn4_11(self.LReLU4_11(self.conv4_11(x)))\n",
    "        x_2 = self.bn4_12(self.LReLU4_12(self.conv4_12(x)))\n",
    "        x_3 = self.bn4_13(self.LReLU4_13(self.conv4_13(x)))\n",
    "        x_4 = self.bn4_14(self.LReLU4_14(self.conv4_14(x)))\n",
    "        x = torch.cat([x_1,x_2,x_3,x_4], dim=1)\n",
    "        x = self.attention_4(x, input) if self.self_attention else x\n",
    "        conv6 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
    "        \n",
    "        # uncomment this block for further downsampling\n",
    "        '''\n",
    "        x = self.bn4_1(self.LReLU4_1(self.conv4_1(x)))\n",
    "        conv4 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
    "        x = self.max_pool4(conv4)\n",
    "\n",
    "        x = self.bn5_1(self.LReLU5_1(self.conv5_1(x)))\n",
    "        #x = x*attention_map5 if self.self_attention else x\n",
    "        x = self.attention_5(x) if self.self_attention else x\n",
    "        conv5 = self.bn5_2(self.LReLU5_2(self.conv5_2(x)))\n",
    "        \n",
    "        conv5 = F_upsample(conv5, scale_factor=2, mode='bilinear')\n",
    "        #conv4 = conv4*attention_map4 if self.self_attention else conv4\n",
    "        conv4 = self.attention_4(conv4) if self.self_attention else conv4\n",
    "        up6 = torch.cat([self.deconv5(conv5), conv4], 1)\n",
    "        x = self.bn6_1(self.LReLU6_1(self.conv6_1(up6)))\n",
    "        conv6 = self.bn6_2(self.LReLU6_2(self.conv6_2(x)))\n",
    "        '''\n",
    "        ########### Ends: Bottom of the U-NET ##########\n",
    "\n",
    "        conv6 = F_upsample(conv6, scale_factor=2, mode='bilinear')\n",
    "        conv3 = self.attention_3(conv3, input) if self.self_attention else conv3\n",
    "        up7 = torch.cat([self.deconv6(conv6), conv3], 1)\n",
    "        x = self.bn7_1(self.LReLU7_1(self.conv7_1(up7)))\n",
    "        conv7 = self.bn7_2(self.LReLU7_2(self.conv7_2(x)))\n",
    "\n",
    "        conv7 = F_upsample(conv7, scale_factor=2, mode='bilinear')\n",
    "        conv2 = self.attention_2(conv2, input) if self.self_attention else conv2\n",
    "        up8 = torch.cat([self.deconv7(conv7), conv2], 1)\n",
    "        x = self.bn8_1(self.LReLU8_1(self.conv8_1(up8)))\n",
    "        conv8 = self.bn8_2(self.LReLU8_2(self.conv8_2(x)))\n",
    "\n",
    "        conv8 = F_upsample(conv8, scale_factor=2, mode='bilinear')\n",
    "        conv1 = self.attention_1(conv1, input) if self.self_attention else conv1\n",
    "        up9 = torch.cat([self.deconv8(conv8), conv1], 1)\n",
    "        x = self.bn9_1(self.LReLU9_1(self.conv9_1(up9)))\n",
    "        conv9 = self.LReLU9_2(self.conv9_2(x))\n",
    "\n",
    "        latent = self.conv10(conv9)\n",
    "        latent = self.attention_out(latent, input) if self.self_attention else latent\n",
    "\n",
    "        if self.skip:\n",
    "            if self.normalize:\n",
    "                min_latent = torch.amin(latent, dim=(0,2,3), keepdim=True)\n",
    "                max_latent = torch.amax(latent, dim=(0,2,3), keepdim=True)\n",
    "                latent = (latent - min_latent) / (max_latent - min_latent)\n",
    "                \n",
    "            output = latent + self.skip * input\n",
    "        else:\n",
    "            output = latent\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            output = self.final_tanh(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [[\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "\n",
    "        sequence += [[\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        sequence += [[nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]]  # output 1 channel prediction map\n",
    "\n",
    "        for n in range(len(sequence)):\n",
    "            setattr(self, 'model' + str(n), nn.Sequential(*sequence[n]))\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        if return_features:\n",
    "            feats = [x]\n",
    "            for n in range(self.n_layers + 2):\n",
    "                feats.append(getattr(self, 'model' + str(n))(feats[-1]))    \n",
    "            return feats[1:]\n",
    "        else:\n",
    "            for n in range(self.n_layers + 2):\n",
    "                x = getattr(self, 'model' + str(n))(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPLoss, self).__init__()\n",
    "        \n",
    "\n",
    "    def __call__(self, input, reference):\n",
    "        a = torch.sum(torch.sum(F.normalize(input, p=2, dim=2) * F.normalize(reference, p=2, dim=2),dim=2, keepdim=True))\n",
    "        b = torch.sum(torch.sum(F.normalize(input, p=2, dim=3) * F.normalize(reference, p=2, dim=3),dim=3, keepdim=True))\n",
    "        return -(a + b) / input.size(2)\n",
    "\n",
    "class GPLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPLoss, self).__init__()\n",
    "        self.trace = SPLoss()\n",
    "  \n",
    "    def get_image_gradients(self,input):        \n",
    "        f_v_1 = F.pad(input,(0,-1,0,0))\n",
    "        f_v_2 = F.pad(input,(-1,0,0,0))\n",
    "        f_v = f_v_1-f_v_2\n",
    "\n",
    "        f_h_1 = F.pad(input,(0,0,0,-1))\n",
    "        f_h_2 = F.pad(input,(0,0,-1,0))\n",
    "        f_h = f_h_1-f_h_2\n",
    "\n",
    "        return f_v, f_h\n",
    "\n",
    "    def __call__(self, input, reference, normalize=True):\n",
    "        if normalize:\n",
    "            input = (input+1)/2\n",
    "            reference = (reference+1)/2\n",
    "\n",
    "        input_v,input_h = self.get_image_gradients(input)\n",
    "        ref_v, ref_h = self.get_image_gradients(reference)\n",
    "\n",
    "        trace_v = self.trace(input_v,ref_v)\n",
    "        trace_h = self.trace(input_h,ref_h)\n",
    "        return trace_v + trace_h\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def MSE_loss_weighted(self, prediction, target, mask):\n",
    "        return (mask * ((prediction - target)**2)).mean()\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real, mask=None):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        ''' \n",
    "        if isinstance(prediction, list):\n",
    "            if isinstance(prediction[0], list):\n",
    "                loss = 0\n",
    "                for pred in prediction:\n",
    "                    loss += self.calculate_loss(pred[-1], target_is_real)\n",
    "                return loss\n",
    "            else:\n",
    "                return self.calculate_loss(prediction[-1], target_is_real)\n",
    "        else:    \n",
    "        '''\n",
    "        return self.calculate_loss(prediction, target_is_real, mask)\n",
    "    \n",
    "    def calculate_loss(self, prediction, target_is_real, mask):\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            if self.gan_mode == 'lsgan' and mask is not None:\n",
    "                mask = F_upsample(mask, size=prediction.shape[-2:])\n",
    "                loss = self.MSE_loss_weighted(prediction, target_tensor, mask)\n",
    "            else:\n",
    "                loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "    \n",
    "def get_optimizer(model,lr, extra_model=None):\n",
    "    \"\"\"Return an optimizer for the model\n",
    "\n",
    "    Parameters:\n",
    "        model               -- model that whose parameters will be optimized \n",
    "        opt (option class)  -- stores all the experiment flags; needs to be a subclass of BaseOptions．\n",
    "                               opt.optim_[model_name] is the name of optimizer: SGD | Adam.　\n",
    "        model_name          -- name of the model, needed for fetching the correct values for the model from opt.　\n",
    "    \"\"\"\n",
    "\n",
    "    learnable_params = list(model.parameters())\n",
    "    if extra_model is not None:\n",
    "        learnable_params += extra_model.parameters()\n",
    "\n",
    "    return torch.optim.Adam(learnable_params, lr=lr, betas=(0.5, 0.999))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulConstant(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor, constant):\n",
    "        # ctx is a context object that can be used to stash information\n",
    "        # for backward computation\n",
    "        ctx.constant = constant\n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # We return as many input gradients as there were arguments.\n",
    "        # Gradients of non-Tensor arguments to forward must be None.\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input = ctx.constant * grad_input\n",
    "        return grad_input, None\n",
    "    \n",
    "class CustomNormalization(nn.Module):\n",
    "    def __init__(self, normalize):\n",
    "        super(CustomNormalization, self).__init__()\n",
    "        self.normalize = normalize\n",
    "        \n",
    "\n",
    "    def forward(self, x, alpha=1.0):\n",
    "        \n",
    "            # this function acts as an identity in the forward pass,\n",
    "            # but scales the gradients in the backward pass.\n",
    "        x = MulConstant.apply(x, alpha)\n",
    "\n",
    "        if self.normalize: \n",
    "            # map the tanh output to 8bit range\n",
    "            x = x + 1\n",
    "            x = x / 2 * 255\n",
    "            # apply the normalization values for the pretrained detection network\n",
    "            x = F_normalize(x, \n",
    "                    [123.675, 116.28, 103.53], \n",
    "                    [58.395, 57.12, 57.375]\n",
    "            )\n",
    "        return x\n",
    "custom_normalization=CustomNormalization(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:{}'.format(torch.cuda.current_device()))      \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "lambda_gpl=0.8\n",
    "lambda_feat=10\n",
    "lambda_gr=0\n",
    "gan_mode='lsgan'\n",
    "norm_layer='instance'\n",
    "lr_Det=5e-4\n",
    "lr_D=2e-4\n",
    "lr_G=2e-4\n",
    "beta1=0.5\n",
    "lr_decay_epoch_Det=30\n",
    "lr_decay_epoch_D=20\n",
    "lr_decay_epoch_G=20\n",
    "n_layers_D=3\n",
    "n_epochs_model=20\n",
    "n_epochs_decay_G=30 \n",
    "n_epochs_decay_D=30 \n",
    "unroll=0\n",
    "lr_policy_D='linear'\n",
    "alpha_disc=1.0\n",
    "alpha_det=1.0\n",
    "alpha_mode_det='cg_id'\n",
    "alpha_epochs_det=5\n",
    "alpha_mode_disc='Det'\n",
    "maximize_detection_loss=True  #generator tries to maximize the detection loss\n",
    "simult_det_update=False #NOT USED. if set, update the generator and detector simultaneouslys\n",
    "input_nc=3\n",
    "output_nc=3\n",
    "feature_matching=True #use feature matching loss on the discriminator\n",
    "lr_start_epoch_Det=0\n",
    "with_detector=True\n",
    "train_on_real=True #train the detector on real images as well\n",
    "freeze_detector=False #If set, detector network is not updated\n",
    "no_disc_loss=False #If set, do not use discriminator loss (only for debugging)\n",
    "#input_nc the number of channels in input images\n",
    "#ndf the number of filters in the first conv layer\n",
    "norm_layer1 = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "netG = UnetGeneratorBilinear(norm_layer=norm_layer).to(device)\n",
    "netD = NLayerDiscriminator(input_nc=input_nc+output_nc,ndf=64,n_layers=3,norm_layer=norm_layer1).to(device)\n",
    "#https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\n",
    "netDet=retinanet_resnet50_fpn(pretrained=True)\n",
    "in_features=netDet.head.classification_head.conv[0].out_channels\n",
    "netDet.head.classification_head=nn.Conv2d(\n",
    "    in_features,\n",
    "    num_classes*netDet.head.classification_head.num_anchors,\n",
    "    kernel_size=(3,3),\n",
    "    stride=(1,1),\n",
    "    padding=(1,1)\n",
    ")\n",
    "netDet=netDet.to(device)\n",
    "criterionGAN = GANLoss(gan_mode).to(device)\n",
    "criterionFeat = nn.L1Loss().to(device)\n",
    "citerionGPL = GPLoss().to(device) \n",
    "l1_loss_func = nn.L1Loss().to(device)\n",
    "class_loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer_D = get_optimizer(netD, lr_D)\n",
    "optimizer_G = get_optimizer(netG, lr_G)\n",
    "optimizer_Det = get_optimizer(netDet,lr_Det)\n",
    "#scheduler, backprop, detector, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad2(disc_out, real_data):\n",
    "    ''' Calculate the gradient norm for regularization. Different from WGAN-GP, norm is zero centered.\n",
    "\n",
    "    Arguments:\n",
    "        disc_out (tensor)           -- discriminator output\n",
    "        real_data (tensor array)    -- real images\n",
    "\n",
    "    Returns the squared gradient norm     \n",
    "    '''\n",
    "    batch_size = real_data.size(0)\n",
    "    grad_dout = torch.autograd.grad(\n",
    "        outputs=disc_out.sum(), inputs=real_data,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    \n",
    "    assert(grad_dout2.size() == real_data.size())\n",
    "    \n",
    "    reg = grad_dout2.view(batch_size, -1).sum(1)\n",
    "    return reg\n",
    "\n",
    "def detect_objects(detach_input=False, current_iter=None, detect_real=False,real_B=None,fake_B=None):\n",
    "        isTrain=True\n",
    "        if current_iter:\n",
    "            if 'ig' in alpha_mode_det:\n",
    "                alpha_weight = current_iter / (alpha_epochs_det*dataset_size)\n",
    "                curr_alpha = float(min(alpha_det, alpha_det * alpha_weight))\n",
    "            else:\n",
    "                curr_alpha = float(alpha_det)\n",
    "        else:\n",
    "            curr_alpha = 1.0\n",
    "\n",
    "        if detect_real:\n",
    "            _to_detector = custom_normalization(real_B, alpha=curr_alpha)\n",
    "        else:\n",
    "            if isTrain and maximize_detection_loss:\n",
    "                curr_alpha = -1 * curr_alpha\n",
    "            _to_detector = custom_normalization(fake_B, alpha=curr_alpha)\n",
    "        \n",
    "        if detach_input:\n",
    "            _to_detector = _to_detector.detach()\n",
    "\n",
    "        detector_out = netDet(_to_detector)\n",
    "        \n",
    "        return detector_out\n",
    "    \n",
    "def parse_detection_loss(register_loss,detector_out,cls_labels,bboxes_true):\n",
    "        losses={}\n",
    "        losses['classification_loss'] = class_loss_func(detector_out[0]['scores'].view(-1, num_classes), cls_labels.view(-1))\n",
    "        losses['bbox_loss'] = l1_loss_func(detector_out[0]['boxes'], bboxes_true)\n",
    "        log_vars = {}\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            log_vars[loss_name] = loss_value.mean()  # Calculating mean might be redundant depending on tensor shape\n",
    "        loss = sum(value for key, value in log_vars.items() if 'loss' in key)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "def _update_D(current_epoch):\n",
    "        '''returns true if the discriminator needs to be updated'''\n",
    "        return (not no_disc_loss and\n",
    "                current_epoch <= n_epochs_model)\n",
    "def _update_Det(current_epoch):\n",
    "        '''returns true if the detector needs to be updated'''\n",
    "        return  (with_detector and not freeze_detector and \n",
    "                current_epoch <= n_epochs_model and \n",
    "                lr_start_epoch_Det <= current_epoch)\n",
    "def _update_G(current_epoch):\n",
    "        '''returns true if the generator needs to be updated'''\n",
    "        return current_epoch <= n_epochs_model\n",
    "def backward_D(real_A,fake_B,real_B):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
    "        optimizer_D.zero_grad() \n",
    "        features = None\n",
    "        # Fake; stop backprop to the generator by detaching fake_B\n",
    "        fake_AB = torch.cat((real_A, fake_B), 1) \n",
    "        pred_fake = netD(fake_AB.detach())\n",
    "        loss_D_fake = criterionGAN(pred_fake, False)\n",
    "        loss_D_fake.backward()\n",
    "\n",
    "        # Real\n",
    "        real_AB = torch.cat((real_A, real_B), 1).requires_grad_()\n",
    "        pred_real = netD(real_AB,feature_matching)\n",
    "        loss_D_real = criterionGAN(pred_real[-1] if feature_matching else pred_real, True, mask=None)\n",
    "        # regularize the discriminator with gradient norm.\n",
    "        if lambda_gr:\n",
    "            loss_D_real.backward(retain_graph=True)\n",
    "            grad_reg = lambda_gr * compute_grad2(pred_real, real_AB).mean()\n",
    "            grad_reg.backward()\n",
    "        else:\n",
    "            loss_D_real.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        return features\n",
    "\n",
    "def backward_G(current_iter, current_epoch,real_A,fake_B,real_B):\n",
    "        \"\"\"Calculate Detection, GAN and L1 loss for the generator\"\"\"\n",
    "        \n",
    "        debug_grads = False\n",
    "        debug_grad_norms=False\n",
    "        # if debug_grad_norms:\n",
    "        #     grads_iter_modulo = current_iter % 400\n",
    "        #     number_of_samples = number_of_iters * batch_size\n",
    "        #     debug_grads = debug_grad_norms and grads_iter_modulo <= number_of_samples \n",
    "        #     is_last = grads_iter_modulo == (number_of_samples)\n",
    "\n",
    "        if _update_G(current_epoch):\n",
    "        \n",
    "            optimizer_G.zero_grad()\n",
    "            ###############################################################################\n",
    "            # #TODO: Decrease the contribution from all discriminator-related losses      # \n",
    "            # proportionally to the decay of the learning rate of discriminator.          #\n",
    "            # I do not do this for now; thus the weight is always 1.                      #\n",
    "            ###############################################################################\n",
    "            \n",
    "            if alpha_mode_disc == 'dec':\n",
    "                if lr_policy_D == 'step':\n",
    "                    disc_weight = 0.1 ** (current_epoch // lr_decay_epoch_D)\n",
    "                    #disc_weight = 0.1 if (current_iter // self.opt.dataset_size) >= self.opt.lr_decay_epoch_D else 1\n",
    "                else:\n",
    "                    if n_epochs_decay_D == 0:\n",
    "                        disc_weight = 1\n",
    "                    else:\n",
    "                        disc_weight = (n_epochs_model*dataset_size - current_iter)/(n_epochs_decay_D*dataset_size)\n",
    "                disc_weight = min(alpha_disc, alpha_disc*disc_weight)\n",
    "            else:\n",
    "                disc_weight = alpha_disc\n",
    "            \n",
    "            use_disc_loss = _update_D(current_epoch)\n",
    "\n",
    "            # overall loss\n",
    "            loss_G = 0\n",
    "\n",
    "            # GAN-related losses\n",
    "            loss_G_GAN = 0\n",
    "            loss_G_GAN_feat = 0\n",
    "            # gradient profile loss (cosine similarity between gradient/edge maps)\n",
    "            loss_G_GPL = 0.\n",
    "            if disc_weight > 0 and use_disc_loss:\n",
    "                # G(A) should fake the discriminator\n",
    "                fake_AB = torch.cat((real_A, fake_B), 1)\n",
    "                pred_fake = netD(fake_AB, feature_matching)\n",
    "                loss_G_GAN = criterionGAN(pred_fake[-1] if feature_matching else pred_fake, True, mask=None)\n",
    "                loss_G = loss_G + loss_G_GAN * disc_weight\n",
    "                # feature matching loss\n",
    "                # match the features of fake and real in the intermediate layers of the discriminator\n",
    "                if feature_matching:\n",
    "                    real_AB = torch.cat((real_A, real_B), 1)\n",
    "                    pred_real = netD(real_AB, return_features=True)\n",
    "                    feat_weights = 4.0 / (n_layers_D + 1)\n",
    "                    for i in range(len(pred_fake)-1):\n",
    "                        loss_G_GAN_feat += feat_weights * criterionFeat(pred_fake[i], \n",
    "                                                                            pred_real[i].detach()) * lambda_feat\n",
    "                    loss_G = loss_G + loss_G_GAN_feat * disc_weight\n",
    "                \n",
    "                if lambda_gpl:\n",
    "                    #TODO: can use either real LDR or HDR as a reference. These options should be compared.\n",
    "                    loss_G_GPL = citerionGPL(fake_B, real_B, normalize=True)\n",
    "                    loss_G = loss_G + loss_G_GPL * lambda_gpl\n",
    "\n",
    "            # Det(G(A)) should detect objects.\n",
    "            if with_detector:    \n",
    "                if unroll > 0:\n",
    "                    # see how detector reacts to real images + fake images \n",
    "                    # by unrolling <unroll> many steps\n",
    "                    backup = copy.deepcopy(netDet.module.state_dict())\n",
    "                    # for _ in range(unroll):\n",
    "                    #     backward_Det_unrolled(current_iter, current_epoch)\n",
    "\n",
    "                # detect objects on generated images to update the generator\n",
    "                optimizer_Det.zero_grad()\n",
    "                detector_out=detect_objects(detach_input=False, current_iter=current_iter,real_B=real_B,fake_B=fake_B)\n",
    "                detector_loss = parse_detection_loss(register_loss=simult_det_update,detector_out=detector_out,cls_labels=None,bboxes_true=None)\n",
    "                loss_G = loss_G + detector_loss\n",
    "            \n",
    "            if not debug_grads:\n",
    "                loss_G.backward()  \n",
    "                optimizer_G.step()\n",
    "\n",
    "            if  unroll > 0:\n",
    "                netDet.module.load_state_dict(backup)    \n",
    "                del backup\n",
    "        \n",
    "        if not debug_grads:\n",
    "            if _update_Det(current_epoch) and simult_det_update:\n",
    "                optimizer_Det.step()\n",
    "\n",
    "def backward_Det(current_iter, current_epoch,real_B,fake_B,cls_labels,bbox):\n",
    "        \n",
    "\n",
    "        optimizer_Det.zero_grad()     \n",
    "\n",
    "        detector_out=detect_objects(detach_input=True, current_iter=current_iter,real_B=real_B,fake_B=fake_B)\n",
    "        detector_loss = parse_detection_loss(register_loss=not maximize_detection_loss,detector_out=detector_out,cls_labels=cls_labels,bboxes_true=bbox)\n",
    "        \n",
    "        if train_on_real:\n",
    "            detector_out=detect_objects(current_iter=current_iter, detect_real=True)\n",
    "            detector_loss_real = parse_detection_loss(register_loss=maximize_detection_loss, detector_out=detector_out,cls_labels=cls_labels,bboxes_true=bbox)\n",
    "            detector_loss = detector_loss + detector_loss_real\n",
    "        \n",
    "        detector_loss.backward()\n",
    "        optimizer_Det.step()\n",
    "\n",
    "def optimize_parameters(current_iter, current_epoch,real_A,real_B):\n",
    "        # compute fake images: G(A)\n",
    "        fake_B = netG(real_A) #forward\n",
    "\n",
    "        # update D\n",
    "        backward_D(real_A,fake_B,real_B)\n",
    "\n",
    "        # update Det\n",
    "        if not simult_det_update:\n",
    "            backward_Det(current_iter, current_epoch,real_B,fake_B)\n",
    "\n",
    "        # update G\n",
    "        backward_G(current_iter, current_epoch,real_A,fake_B,real_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=30\n",
    "for epoch in range(n_epochs):\n",
    "    optimize_parameters(epoch,real_A,real_B)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
