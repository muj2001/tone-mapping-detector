{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torchvision.transforms.functional import normalize as F_normalize\n",
    "from torch.nn.functional import interpolate as F_upsample\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientAttention(nn.Module):\n",
    "    def __init__(self, val_channels=3, key_channels=4, in_channels=0):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels if in_channels else val_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.val_channels = val_channels\n",
    "\n",
    "        self.keys = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
    "        self.values = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
    "        self.queries = nn.Conv2d(self.in_channels, self.key_channels, 1)\n",
    "        self.reprojection = nn.Conv2d(self.key_channels, self.val_channels, 1)\n",
    "\n",
    "    def forward(self, value_, input_=None):\n",
    "        n, c, h, w = value_.size()\n",
    "        values = self.values(value_).reshape((n, self.key_channels, h * w))\n",
    "        keys = self.keys(value_).reshape((n, self.key_channels, h * w))\n",
    "        \n",
    "        if input_ is not None:\n",
    "            queries = self.queries(input_)\n",
    "            \n",
    "            # maxpool the query if it is larger than the value \n",
    "            _, _, h_i, w_i = input_.size()\n",
    "            if w_i > w or h_i > h:\n",
    "                queries = F.max_pool2d(queries, (h_i//h, w_i//w))\n",
    "            \n",
    "            queries = queries.reshape(n, self.key_channels, h * w)\n",
    "        else:\n",
    "            queries = self.queries(value_).reshape(n, self.key_channels, h * w)\n",
    "\n",
    "        key = F.softmax(keys, dim=2)\n",
    "        query = F.softmax(queries, dim=1)\n",
    "        \n",
    "        context = key @ values.transpose(1, 2)\n",
    "        attention = (\n",
    "            context.transpose(1, 2) @ query\n",
    "        ).reshape(n, self.key_channels, h, w)\n",
    "\n",
    "        reprojected_value = self.reprojection(attention)\n",
    "        attention = reprojected_value + value_\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGeneratorBilinear(nn.Module):\n",
    "    def __init__(self, opt, norm_layer):\n",
    "        super(UnetGeneratorBilinear, self).__init__()\n",
    "\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        \n",
    "        self.normalize = opt.norm_G_out\n",
    "        self.self_attention = opt.self_attention\n",
    "        self.use_avgpool = opt.use_avgpool\n",
    "        self.skip = opt.skip\n",
    "        self.use_tanh = opt.tanh_G_out\n",
    "        if self.use_tanh:\n",
    "            if opt.hardtanh:\n",
    "                self.final_tanh = nn.Hardtanh() \n",
    "            else:\n",
    "                self.final_tanh = nn.Tanh() \n",
    "\n",
    "        p = 1\n",
    "        if self.self_attention:\n",
    "            self.conv1_1 = nn.Conv2d(6, 32, 3, padding=p)\n",
    "            self.attention_in = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
    "            self.attention_out = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
    "            self.attention_1 = EfficientAttention(val_channels=32, key_channels=4, in_channels=3)\n",
    "            self.attention_2 = EfficientAttention(val_channels=64, key_channels=4, in_channels=3)\n",
    "            self.attention_3 = EfficientAttention(val_channels=128, key_channels=8, in_channels=3)\n",
    "            self.attention_4 = EfficientAttention(val_channels=512, key_channels=16, in_channels=3)\n",
    "        else:\n",
    "            self.conv1_1 = nn.Conv2d(3, 32, 3, padding=p)\n",
    "\n",
    "        self.LReLU1_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn1_1 = norm_layer(32)\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
    "        self.LReLU1_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn1_2 = norm_layer(32)\n",
    "        self.max_pool1 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, 3, padding=p)\n",
    "        self.LReLU2_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn2_1 = norm_layer(64)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
    "        self.LReLU2_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn2_2 = norm_layer(64)\n",
    "        self.max_pool2 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(64, 128, 3, padding=p)\n",
    "        self.LReLU3_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn3_1 = norm_layer(128)\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
    "        self.LReLU3_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn3_2 = norm_layer(128)\n",
    "        self.max_pool3 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4_11 = nn.Conv2d(128, 128, 1, padding=p*0)\n",
    "        self.LReLU4_11 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_11 = norm_layer(128)\n",
    "        self.conv4_12 = nn.Conv2d(128, 128, 3, padding=p*1)\n",
    "        self.LReLU4_12 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_12 = norm_layer(128)\n",
    "        self.conv4_13 = nn.Conv2d(128, 128, 5, padding=p*2)\n",
    "        self.LReLU4_13 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_13 = norm_layer(128)\n",
    "        self.conv4_14 = nn.Conv2d(128, 128, 7, padding=p*3)\n",
    "        self.LReLU4_14 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_14 = norm_layer(128)\n",
    "        self.conv4_2 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.LReLU4_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn4_2 = norm_layer(256)\n",
    "        \n",
    "        \n",
    "        # Uncomment this block for further downsampling\n",
    "        '''\n",
    "        self.max_pool4 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(256, 512, 3, padding=p)\n",
    "        self.LReLU5_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn5_1 = norm_layer(512)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=p)\n",
    "        self.LReLU5_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn5_2 = norm_layer(512)\n",
    "\n",
    "        \n",
    "        self.deconv5 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.conv6_1 = nn.Conv2d(512, 256, 3, padding=p)\n",
    "        self.LReLU6_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn6_1 = norm_layer(256)\n",
    "        self.conv6_2 = nn.Conv2d(256, 256, 3, padding=p)\n",
    "        self.LReLU6_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn6_2 = norm_layer(256)\n",
    "        '''\n",
    "\n",
    "        self.deconv6 = nn.Conv2d(256, 128, 3, padding=p)\n",
    "        self.conv7_1 = nn.Conv2d(256, 128, 3, padding=p)\n",
    "        self.LReLU7_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn7_1 = norm_layer(128)\n",
    "        self.conv7_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
    "        self.LReLU7_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn7_2 = norm_layer(128)\n",
    "\n",
    "        self.deconv7 = nn.Conv2d(128, 64, 3, padding=p)\n",
    "        self.conv8_1 = nn.Conv2d(128, 64, 3, padding=p)\n",
    "        self.LReLU8_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn8_1 = norm_layer(64)\n",
    "        self.conv8_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
    "        self.LReLU8_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn8_2 = norm_layer(64)\n",
    "\n",
    "        self.deconv8 = nn.Conv2d(64, 32, 3, padding=p)\n",
    "        self.conv9_1 = nn.Conv2d(64, 32, 3, padding=p)\n",
    "        self.LReLU9_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn9_1 = norm_layer(32)\n",
    "        self.conv9_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
    "        self.LReLU9_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(32, 3, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.self_attention:\n",
    "            attended_inp = self.attention_in(input)\n",
    "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(torch.cat([input, attended_inp], dim=1))))\n",
    "        else:\n",
    "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(input)))\n",
    "        conv1 = self.bn1_2(self.LReLU1_2(self.conv1_2(x)))\n",
    "        x = self.max_pool1(conv1)\n",
    "\n",
    "        x = self.bn2_1(self.LReLU2_1(self.conv2_1(x)))\n",
    "        conv2 = self.bn2_2(self.LReLU2_2(self.conv2_2(x)))\n",
    "        x = self.max_pool2(conv2)\n",
    "\n",
    "        x = self.bn3_1(self.LReLU3_1(self.conv3_1(x)))\n",
    "        conv3 = self.bn3_2(self.LReLU3_2(self.conv3_2(x)))\n",
    "        x = self.max_pool3(conv3)\n",
    "\n",
    "        ########## Starts: Bottom of the U-NET ##########\n",
    "        x_1 = self.bn4_11(self.LReLU4_11(self.conv4_11(x)))\n",
    "        x_2 = self.bn4_12(self.LReLU4_12(self.conv4_12(x)))\n",
    "        x_3 = self.bn4_13(self.LReLU4_13(self.conv4_13(x)))\n",
    "        x_4 = self.bn4_14(self.LReLU4_14(self.conv4_14(x)))\n",
    "        x = torch.cat([x_1,x_2,x_3,x_4], dim=1)\n",
    "        x = self.attention_4(x, input) if self.self_attention else x\n",
    "        conv6 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
    "        \n",
    "        # uncomment this block for further downsampling\n",
    "        '''\n",
    "        x = self.bn4_1(self.LReLU4_1(self.conv4_1(x)))\n",
    "        conv4 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
    "        x = self.max_pool4(conv4)\n",
    "\n",
    "        x = self.bn5_1(self.LReLU5_1(self.conv5_1(x)))\n",
    "        #x = x*attention_map5 if self.self_attention else x\n",
    "        x = self.attention_5(x) if self.self_attention else x\n",
    "        conv5 = self.bn5_2(self.LReLU5_2(self.conv5_2(x)))\n",
    "        \n",
    "        conv5 = F_upsample(conv5, scale_factor=2, mode='bilinear')\n",
    "        #conv4 = conv4*attention_map4 if self.self_attention else conv4\n",
    "        conv4 = self.attention_4(conv4) if self.self_attention else conv4\n",
    "        up6 = torch.cat([self.deconv5(conv5), conv4], 1)\n",
    "        x = self.bn6_1(self.LReLU6_1(self.conv6_1(up6)))\n",
    "        conv6 = self.bn6_2(self.LReLU6_2(self.conv6_2(x)))\n",
    "        '''\n",
    "        ########### Ends: Bottom of the U-NET ##########\n",
    "\n",
    "        conv6 = F_upsample(conv6, scale_factor=2, mode='bilinear')\n",
    "        conv3 = self.attention_3(conv3, input) if self.self_attention else conv3\n",
    "        up7 = torch.cat([self.deconv6(conv6), conv3], 1)\n",
    "        x = self.bn7_1(self.LReLU7_1(self.conv7_1(up7)))\n",
    "        conv7 = self.bn7_2(self.LReLU7_2(self.conv7_2(x)))\n",
    "\n",
    "        conv7 = F_upsample(conv7, scale_factor=2, mode='bilinear')\n",
    "        conv2 = self.attention_2(conv2, input) if self.self_attention else conv2\n",
    "        up8 = torch.cat([self.deconv7(conv7), conv2], 1)\n",
    "        x = self.bn8_1(self.LReLU8_1(self.conv8_1(up8)))\n",
    "        conv8 = self.bn8_2(self.LReLU8_2(self.conv8_2(x)))\n",
    "\n",
    "        conv8 = F_upsample(conv8, scale_factor=2, mode='bilinear')\n",
    "        conv1 = self.attention_1(conv1, input) if self.self_attention else conv1\n",
    "        up9 = torch.cat([self.deconv8(conv8), conv1], 1)\n",
    "        x = self.bn9_1(self.LReLU9_1(self.conv9_1(up9)))\n",
    "        conv9 = self.LReLU9_2(self.conv9_2(x))\n",
    "\n",
    "        latent = self.conv10(conv9)\n",
    "        latent = self.attention_out(latent, input) if self.self_attention else latent\n",
    "\n",
    "        if self.skip:\n",
    "            if self.normalize:\n",
    "                min_latent = torch.amin(latent, dim=(0,2,3), keepdim=True)\n",
    "                max_latent = torch.amax(latent, dim=(0,2,3), keepdim=True)\n",
    "                latent = (latent - min_latent) / (max_latent - min_latent)\n",
    "                \n",
    "            output = latent + self.skip * input\n",
    "        else:\n",
    "            output = latent\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            output = self.final_tanh(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [[\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "\n",
    "        sequence += [[\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        sequence += [[nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]]  # output 1 channel prediction map\n",
    "\n",
    "        for n in range(len(sequence)):\n",
    "            setattr(self, 'model' + str(n), nn.Sequential(*sequence[n]))\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        if return_features:\n",
    "            feats = [x]\n",
    "            for n in range(self.n_layers + 2):\n",
    "                feats.append(getattr(self, 'model' + str(n))(feats[-1]))    \n",
    "            return feats[1:]\n",
    "        else:\n",
    "            for n in range(self.n_layers + 2):\n",
    "                x = getattr(self, 'model' + str(n))(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\n",
    "netDet=torchvision.models.detection.retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPLoss, self).__init__()\n",
    "        \n",
    "\n",
    "    def __call__(self, input, reference):\n",
    "        a = torch.sum(torch.sum(F.normalize(input, p=2, dim=2) * F.normalize(reference, p=2, dim=2),dim=2, keepdim=True))\n",
    "        b = torch.sum(torch.sum(F.normalize(input, p=2, dim=3) * F.normalize(reference, p=2, dim=3),dim=3, keepdim=True))\n",
    "        return -(a + b) / input.size(2)\n",
    "\n",
    "class GPLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPLoss, self).__init__()\n",
    "        self.trace = SPLoss()\n",
    "  \n",
    "    def get_image_gradients(self,input):        \n",
    "        f_v_1 = F.pad(input,(0,-1,0,0))\n",
    "        f_v_2 = F.pad(input,(-1,0,0,0))\n",
    "        f_v = f_v_1-f_v_2\n",
    "\n",
    "        f_h_1 = F.pad(input,(0,0,0,-1))\n",
    "        f_h_2 = F.pad(input,(0,0,-1,0))\n",
    "        f_h = f_h_1-f_h_2\n",
    "\n",
    "        return f_v, f_h\n",
    "\n",
    "    def __call__(self, input, reference, normalize=True):\n",
    "        if normalize:\n",
    "            input = (input+1)/2\n",
    "            reference = (reference+1)/2\n",
    "\n",
    "        input_v,input_h = self.get_image_gradients(input)\n",
    "        ref_v, ref_h = self.get_image_gradients(reference)\n",
    "\n",
    "        trace_v = self.trace(input_v,ref_v)\n",
    "        trace_h = self.trace(input_h,ref_h)\n",
    "        return trace_v + trace_h\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def MSE_loss_weighted(self, prediction, target, mask):\n",
    "        return (mask * ((prediction - target)**2)).mean()\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real, mask=None):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        ''' \n",
    "        if isinstance(prediction, list):\n",
    "            if isinstance(prediction[0], list):\n",
    "                loss = 0\n",
    "                for pred in prediction:\n",
    "                    loss += self.calculate_loss(pred[-1], target_is_real)\n",
    "                return loss\n",
    "            else:\n",
    "                return self.calculate_loss(prediction[-1], target_is_real)\n",
    "        else:    \n",
    "        '''\n",
    "        return self.calculate_loss(prediction, target_is_real, mask)\n",
    "    \n",
    "    def calculate_loss(self, prediction, target_is_real, mask):\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            if self.gan_mode == 'lsgan' and mask is not None:\n",
    "                mask = F_upsample(mask, size=prediction.shape[-2:])\n",
    "                loss = self.MSE_loss_weighted(prediction, target_tensor, mask)\n",
    "            else:\n",
    "                loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "    \n",
    "def get_optimizer(model, opt, model_name, extra_model=None):\n",
    "    \"\"\"Return an optimizer for the model\n",
    "\n",
    "    Parameters:\n",
    "        model               -- model that whose parameters will be optimized \n",
    "        opt (option class)  -- stores all the experiment flags; needs to be a subclass of BaseOptions．\n",
    "                               opt.optim_[model_name] is the name of optimizer: SGD | Adam.　\n",
    "        model_name          -- name of the model, needed for fetching the correct values for the model from opt.　\n",
    "    \"\"\"\n",
    "\n",
    "    optim_choice = getattr(opt, \"optim_\" + model_name)\n",
    "    lr = getattr(opt, \"lr_\" + model_name)\n",
    "    \n",
    "    learnable_params = list(model.parameters())\n",
    "    if extra_model is not None:\n",
    "        learnable_params += extra_model.parameters()\n",
    "\n",
    "    return torch.optim.Adam(learnable_params, lr=lr, betas=(opt.beta1, 0.999))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:{}'.format(torch.cuda.current_device()))      \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "netG = UnetGeneratorBilinear()\n",
    "netD = NLayerDiscriminator()\n",
    "criterionGAN = GANLoss(opt.gan_mode).to(device)\n",
    "criterionFeat = torch.nn.L1Loss()\n",
    "citerionGPL = GPLoss().to(device) \n",
    "\n",
    "optimizer_D = get_optimizer(netD, opt, model_name=\"D\")\n",
    "optimizer_G = get_optimizer(netG, opt, model_name=\"G\")\n",
    "optimizer_Det = get_optimizer(netDet,opt,\"Det\")\n",
    "#scheduler, backprop, detector, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_D(real_A,fake_B,real_B):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
    "        \n",
    "\n",
    "        optimizer_D.zero_grad() \n",
    "\n",
    "        features = None\n",
    "        # Fake; stop backprop to the generator by detaching fake_B\n",
    "        fake_AB = torch.cat((real_A, fake_B), 1) \n",
    "        pred_fake = netD(fake_AB.detach())\n",
    "        loss_D_fake = criterionGAN(pred_fake, False)\n",
    "        loss_D_fake.backward()\n",
    "\n",
    "        # Real\n",
    "        real_AB = torch.cat((real_A, real_B), 1).requires_grad_()\n",
    "        pred_real = netD(real_AB, opt.feature_matching)\n",
    "        loss_D_real = criterionGAN(pred_real[-1] if opt.feature_matching else pred_real, True, mask)\n",
    "        # regularize the discriminator with gradient norm.\n",
    "        if sopt.lambda_gr:\n",
    "            loss_D_real.backward(retain_graph=True)\n",
    "            grad_reg = opt.lambda_GR * networks.compute_grad2(pred_real, real_AB).mean()\n",
    "            grad_reg.backward()\n",
    "        else:\n",
    "            loss_D_real.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        return features\n",
    "\n",
    "def backward_G(self, current_iter, current_epoch):\n",
    "        \"\"\"Calculate Detection, GAN and L1 loss for the generator\"\"\"\n",
    "        \n",
    "        debug_grads = False\n",
    "        if self.opt.debug_grad_norms:\n",
    "            grads_iter_modulo = current_iter % 400\n",
    "            number_of_samples = self.number_of_iters * self.opt.batch_size\n",
    "            debug_grads = self.opt.debug_grad_norms and grads_iter_modulo <= number_of_samples \n",
    "            is_last = grads_iter_modulo == (number_of_samples)\n",
    "\n",
    "        if self._update_G(current_epoch):\n",
    "        \n",
    "            self.optimizer_G.zero_grad()\n",
    "            ###############################################################################\n",
    "            # #TODO: Decrease the contribution from all discriminator-related losses      # \n",
    "            # proportionally to the decay of the learning rate of discriminator.          #\n",
    "            # I do not do this for now; thus the weight is always 1.                      #\n",
    "            ###############################################################################\n",
    "            \n",
    "            if self.opt.alpha_mode_disc == 'dec':\n",
    "                if self.opt.lr_policy_D == 'step':\n",
    "                    disc_weight = 0.1 ** (current_epoch // self.opt.lr_decay_epoch_D)\n",
    "                    #disc_weight = 0.1 if (current_iter // self.opt.dataset_size) >= self.opt.lr_decay_epoch_D else 1\n",
    "                else:\n",
    "                    if self.opt.n_epochs_decay_D == 0:\n",
    "                        disc_weight = 1\n",
    "                    else:\n",
    "                        disc_weight = (self.opt.epochs_per_model['D']*self.opt.dataset_size - current_iter)/(self.opt.n_epochs_decay_D*self.opt.dataset_size)\n",
    "                disc_weight = min(self.opt.alpha_disc, self.opt.alpha_disc*disc_weight)\n",
    "            else:\n",
    "                disc_weight = self.opt.alpha_disc\n",
    "            \n",
    "            use_disc_loss = self._update_D(current_epoch)\n",
    "\n",
    "            # overall loss\n",
    "            loss_G = 0\n",
    "\n",
    "            # GAN-related losses\n",
    "            self.loss_G_GAN = 0\n",
    "            self.loss_G_GAN_feat = 0\n",
    "            # gradient profile loss (cosine similarity between gradient/edge maps)\n",
    "            self.loss_G_GPL = 0.\n",
    "            if disc_weight > 0 and use_disc_loss:\n",
    "                # G(A) should fake the discriminator\n",
    "                fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n",
    "                pred_fake = self.netD(fake_AB, self.opt.feature_matching)\n",
    "                self.loss_G_GAN = self.criterionGAN(pred_fake[-1] if self.opt.feature_matching else pred_fake, True, self.mask)\n",
    "\n",
    "                if debug_grads:\n",
    "                    self.optimizer_G.zero_grad()\n",
    "                    curr_loss = self.loss_G_GAN * disc_weight\n",
    "                    curr_loss.backward(retain_graph=True)\n",
    "                    plot_grad_flow(\n",
    "                        self.netG.module.named_parameters(),\n",
    "                        self.grad_dict[\"Discriminator\"],\n",
    "                        'Generator Gradients from Discriminator ({:.2f})'.format(disc_weight),\n",
    "                        os.path.join(\n",
    "                            self.grad_plot_dir,\n",
    "                            'generator_gradnorm_discriminator-{:.2f}_it-{}.png'.format(disc_weight, current_iter)),\n",
    "                        plot=is_last\n",
    "                    )\n",
    "                    if is_last:\n",
    "                        self.grad_dict[\"Discriminator\"] = OrderedDict()\n",
    "                else:\n",
    "                    loss_G = loss_G + self.loss_G_GAN * disc_weight\n",
    "\n",
    "\n",
    "                # feature matching loss\n",
    "                # match the features of fake and real in the intermediate layers of the discriminator\n",
    "                if self.opt.feature_matching:\n",
    "                    real_AB = torch.cat((self.real_A, self.real_B), 1)\n",
    "                    pred_real = self.netD(real_AB, return_features=True)\n",
    "                    feat_weights = 4.0 / (self.n_layers_D + 1)\n",
    "                    for i in range(len(pred_fake)-1):\n",
    "                        self.loss_G_GAN_feat += feat_weights * self.criterionFeat(pred_fake[i], \n",
    "                                                                            pred_real[i].detach()) * self.opt.lambda_feat\n",
    "\n",
    "                    if debug_grads:\n",
    "                        self.optimizer_G.zero_grad()\n",
    "                        curr_loss = self.loss_G_GAN_feat * disc_weight\n",
    "                        curr_loss.backward(retain_graph=True)\n",
    "                        plot_grad_flow(\n",
    "                            self.netG.module.named_parameters(), \n",
    "                            self.grad_dict[\"FM\"],\n",
    "                            'Generator Gradients from Feature-Matching ({:.2f})'.format(self.opt.lambda_feat),\n",
    "                            os.path.join(\n",
    "                                self.grad_plot_dir,\n",
    "                                'generator_gradnorm_FM-{:.2f}_it-{}.png'.format(self.opt.lambda_feat, current_iter)\n",
    "                            ),\n",
    "                            plot=is_last\n",
    "                        )\n",
    "                        if is_last:\n",
    "                            self.grad_dict[\"FM\"] = OrderedDict()\n",
    "                    else:\n",
    "                        loss_G = loss_G + self.loss_G_GAN_feat * disc_weight\n",
    "                \n",
    "                if self.opt.lambda_gpl:\n",
    "                    #TODO: can use either real LDR or HDR as a reference. These options should be compared.\n",
    "                    self.loss_G_GPL = self.citerionGPL(self.fake_B, self.real_B, normalize=True)\n",
    "\n",
    "                    if debug_grads:\n",
    "                        self.optimizer_G.zero_grad()\n",
    "                        curr_loss = self.loss_G_GPL * self.opt.lambda_gpl\n",
    "                        curr_loss.backward(retain_graph=True)\n",
    "                        plot_grad_flow(\n",
    "                            self.netG.module.named_parameters(),\n",
    "                            self.grad_dict[\"GPL\"],\n",
    "                            'Generator Gradients from Gradient-Profile ({:.2f})'.format(self.opt.lambda_gpl),\n",
    "                            os.path.join(\n",
    "                                self.grad_plot_dir,\n",
    "                                'generator_gradnorm_GPL-{:.2f}_it-{}.png'.format(self.opt.lambda_gpl, current_iter)\n",
    "                            ),\n",
    "                            plot=is_last\n",
    "                        )\n",
    "                        if is_last:\n",
    "                            self.grad_dict[\"GPL\"] = OrderedDict()\n",
    "                    else:\n",
    "                        loss_G = loss_G + self.loss_G_GPL * self.opt.lambda_gpl\n",
    "\n",
    "            # Det(G(A)) should detect objects.\n",
    "            if self.with_detector:    \n",
    "                if self.opt.unroll > 0:\n",
    "                    # see how detector reacts to real images + fake images \n",
    "                    # by unrolling <unroll> many steps\n",
    "                    backup = copy.deepcopy(self.netDet.module.state_dict())\n",
    "                    for _ in range(self.opt.unroll):\n",
    "                        self.backward_Det_unrolled(current_iter, current_epoch)\n",
    "\n",
    "                # detect objects on generated images to update the generator\n",
    "                self.optimizer_Det.zero_grad()\n",
    "                self.detect_objects(detach_input=False, current_iter=current_iter)\n",
    "                detector_loss, log_vars = self.parse_detection_loss(register_loss=self.opt.simult_det_update)\n",
    "\n",
    "                if debug_grads:\n",
    "                    self.optimizer_G.zero_grad()\n",
    "                    detector_loss.backward(retain_graph=True)\n",
    "                    plot_grad_flow(\n",
    "                        self.netG.module.named_parameters(),\n",
    "                        self.grad_dict[\"Detector\"],\n",
    "                        'Generator Gradients from Detector ({:.2f})'.format(self.opt.alpha_det),\n",
    "                        os.path.join(\n",
    "                            self.grad_plot_dir,\n",
    "                            'generator_gradnorm_detector-{:.2f}_it-{}.png'.format(self.opt.alpha_det, current_iter)\n",
    "                        ),\n",
    "                        plot=is_last\n",
    "                    )\n",
    "                    if is_last:\n",
    "                        self.grad_dict[\"Detector\"] = OrderedDict()\n",
    "                else:\n",
    "                    loss_G = loss_G + detector_loss\n",
    "            \n",
    "            if not debug_grads:\n",
    "                loss_G.backward()  \n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            if self.opt.unroll > 0:\n",
    "                self.netDet.module.load_state_dict(backup)    \n",
    "                del backup\n",
    "        \n",
    "        if not debug_grads:\n",
    "            if self._update_Det(current_epoch) and self.opt.simult_det_update:\n",
    "                self.optimizer_Det.step()\n",
    "\n",
    "def backward_Det(self, current_iter, current_epoch):\n",
    "        \n",
    "\n",
    "        optimizer_Det.zero_grad()     \n",
    "\n",
    "        self.detect_objects(detach_input=True, current_iter=current_iter)\n",
    "        detector_loss, log_vars = self.parse_detection_loss(\n",
    "                                        register_loss=not self.opt.maximize_detection_loss)\n",
    "        \n",
    "        if self.opt.train_on_real:\n",
    "            self.detect_objects(current_iter=current_iter, detect_real=True)\n",
    "            detector_loss_real, log_vars_real = self.parse_detection_loss(\n",
    "                                        register_loss=self.opt.maximize_detection_loss)\n",
    "            detector_loss = detector_loss + detector_loss_real\n",
    "        \n",
    "        detector_loss.backward()\n",
    "        optimizer_Det.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A=None #HDR images\n",
    "real_B=None #LDR images\n",
    "fake_B=netG(real_A) #forward\n",
    "backward_D(real_A,fake_B,real_B )\n",
    "backward_Det(current_iter, current_epoch)\n",
    "backward_G(current_iter, current_epoch)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
