{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DLWh15hHKGjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebac7c42-771c-4078-db2d-f9dc7c884970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install OpenEXR Imath\n",
        "# !pip install opencv-python\n",
        "import torch\n",
        "import OpenEXR, Imath\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import normalize as F_normalize\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import retinanet_resnet50_fpn\n",
        "import torchvision\n",
        "import functools\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import interpolate as F_upsample\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qRgD3sOPp2GS"
      },
      "outputs": [],
      "source": [
        "class EfficientAttention(nn.Module):\n",
        "    def __init__(self, val_channels=3, key_channels=4, in_channels=0):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels if in_channels else val_channels\n",
        "        self.key_channels = key_channels\n",
        "        self.val_channels = val_channels\n",
        "\n",
        "        self.keys = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
        "        self.values = nn.Conv2d(self.val_channels, self.key_channels, 1)\n",
        "        self.queries = nn.Conv2d(self.in_channels, self.key_channels, 1)\n",
        "        self.reprojection = nn.Conv2d(self.key_channels, self.val_channels, 1)\n",
        "\n",
        "    def forward(self, value_, input_=None):\n",
        "        n, c, h, w = value_.size()\n",
        "        values = self.values(value_).reshape((n, self.key_channels, h * w))\n",
        "        keys = self.keys(value_).reshape((n, self.key_channels, h * w))\n",
        "\n",
        "        if input_ is not None:\n",
        "            queries = self.queries(input_)\n",
        "\n",
        "            # maxpool the query if it is larger than the value\n",
        "            _, _, h_i, w_i = input_.size()\n",
        "            if w_i > w or h_i > h:\n",
        "                queries = F.max_pool2d(queries, (h_i//h, w_i//w))\n",
        "\n",
        "            queries = queries.reshape(n, self.key_channels, h * w)\n",
        "        else:\n",
        "            queries = self.queries(value_).reshape(n, self.key_channels, h * w)\n",
        "\n",
        "        key = F.softmax(keys, dim=2)\n",
        "        query = F.softmax(queries, dim=1)\n",
        "\n",
        "        context = key @ values.transpose(1, 2)\n",
        "        attention = (\n",
        "            context.transpose(1, 2) @ query\n",
        "        ).reshape(n, self.key_channels, h, w)\n",
        "\n",
        "        reprojected_value = self.reprojection(attention)\n",
        "        attention = reprojected_value + value_\n",
        "        return attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A8fmcFEip2GT"
      },
      "outputs": [],
      "source": [
        "class UnetGeneratorBilinear(nn.Module):\n",
        "    def __init__(self, norm_layer):\n",
        "        super(UnetGeneratorBilinear, self).__init__()\n",
        "\n",
        "        use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        self.normalize = True\n",
        "        self.self_attention = True\n",
        "        self.use_avgpool = True\n",
        "        self.skip = 0.8\n",
        "        self.use_tanh = True\n",
        "        # if self.use_tanh:\n",
        "        #     if opt.hardtanh:\n",
        "        self.final_tanh = nn.Hardtanh()\n",
        "            # else:\n",
        "            #     self.final_tanh = nn.Tanh()\n",
        "\n",
        "        p = 1\n",
        "        if self.self_attention:\n",
        "            self.conv1_1 = nn.Conv2d(6, 32, 3, padding=p)\n",
        "            self.attention_in = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
        "            self.attention_out = EfficientAttention(val_channels=3, key_channels=3, in_channels=3)\n",
        "            self.attention_1 = EfficientAttention(val_channels=32, key_channels=4, in_channels=3)\n",
        "            self.attention_2 = EfficientAttention(val_channels=64, key_channels=4, in_channels=3)\n",
        "            self.attention_3 = EfficientAttention(val_channels=128, key_channels=8, in_channels=3)\n",
        "            self.attention_4 = EfficientAttention(val_channels=512, key_channels=16, in_channels=3)\n",
        "        else:\n",
        "            self.conv1_1 = nn.Conv2d(3, 32, 3, padding=p)\n",
        "\n",
        "        self.LReLU1_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn1_1 = norm_layer(32)\n",
        "        self.conv1_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
        "        self.LReLU1_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn1_2 = norm_layer(32)\n",
        "        self.max_pool1 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(32, 64, 3, padding=p)\n",
        "        self.LReLU2_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn2_1 = norm_layer(64)\n",
        "        self.conv2_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
        "        self.LReLU2_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn2_2 = norm_layer(64)\n",
        "        self.max_pool2 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(64, 128, 3, padding=p)\n",
        "        self.LReLU3_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn3_1 = norm_layer(128)\n",
        "        self.conv3_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
        "        self.LReLU3_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn3_2 = norm_layer(128)\n",
        "        self.max_pool3 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv4_11 = nn.Conv2d(128, 128, 1, padding=p*0)\n",
        "        self.LReLU4_11 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn4_11 = norm_layer(128)\n",
        "        self.conv4_12 = nn.Conv2d(128, 128, 3, padding=p*1)\n",
        "        self.LReLU4_12 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn4_12 = norm_layer(128)\n",
        "        self.conv4_13 = nn.Conv2d(128, 128, 5, padding=p*2)\n",
        "        self.LReLU4_13 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn4_13 = norm_layer(128)\n",
        "        self.conv4_14 = nn.Conv2d(128, 128, 7, padding=p*3)\n",
        "        self.LReLU4_14 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn4_14 = norm_layer(128)\n",
        "        self.conv4_2 = nn.Conv2d(512, 256, 3, padding=p)\n",
        "        self.LReLU4_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn4_2 = norm_layer(256)\n",
        "\n",
        "\n",
        "        # Uncomment this block for further downsampling\n",
        "        '''\n",
        "        self.max_pool4 = nn.AvgPool2d(2) if self.use_avgpool == 1 else nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(256, 512, 3, padding=p)\n",
        "        self.LReLU5_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn5_1 = norm_layer(512)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=p)\n",
        "        self.LReLU5_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn5_2 = norm_layer(512)\n",
        "\n",
        "\n",
        "        self.deconv5 = nn.Conv2d(512, 256, 3, padding=p)\n",
        "        self.conv6_1 = nn.Conv2d(512, 256, 3, padding=p)\n",
        "        self.LReLU6_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn6_1 = norm_layer(256)\n",
        "        self.conv6_2 = nn.Conv2d(256, 256, 3, padding=p)\n",
        "        self.LReLU6_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn6_2 = norm_layer(256)\n",
        "        '''\n",
        "\n",
        "        self.deconv6 = nn.Conv2d(256, 128, 3, padding=p)\n",
        "        self.conv7_1 = nn.Conv2d(256, 128, 3, padding=p)\n",
        "        self.LReLU7_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn7_1 = norm_layer(128)\n",
        "        self.conv7_2 = nn.Conv2d(128, 128, 3, padding=p)\n",
        "        self.LReLU7_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn7_2 = norm_layer(128)\n",
        "\n",
        "        self.deconv7 = nn.Conv2d(128, 64, 3, padding=p)\n",
        "        self.conv8_1 = nn.Conv2d(128, 64, 3, padding=p)\n",
        "        self.LReLU8_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn8_1 = norm_layer(64)\n",
        "        self.conv8_2 = nn.Conv2d(64, 64, 3, padding=p)\n",
        "        self.LReLU8_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn8_2 = norm_layer(64)\n",
        "\n",
        "        self.deconv8 = nn.Conv2d(64, 32, 3, padding=p)\n",
        "        self.conv9_1 = nn.Conv2d(64, 32, 3, padding=p)\n",
        "        self.LReLU9_1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.bn9_1 = norm_layer(32)\n",
        "        self.conv9_2 = nn.Conv2d(32, 32, 3, padding=p)\n",
        "        self.LReLU9_2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "        self.conv10 = nn.Conv2d(32, 3, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.self_attention:\n",
        "            attended_inp = self.attention_in(input)\n",
        "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(torch.cat([input, attended_inp], dim=1))))\n",
        "        else:\n",
        "            x = self.bn1_1(self.LReLU1_1(self.conv1_1(input)))\n",
        "        conv1 = self.bn1_2(self.LReLU1_2(self.conv1_2(x)))\n",
        "        x = self.max_pool1(conv1)\n",
        "\n",
        "        x = self.bn2_1(self.LReLU2_1(self.conv2_1(x)))\n",
        "        conv2 = self.bn2_2(self.LReLU2_2(self.conv2_2(x)))\n",
        "        x = self.max_pool2(conv2)\n",
        "\n",
        "        x = self.bn3_1(self.LReLU3_1(self.conv3_1(x)))\n",
        "        conv3 = self.bn3_2(self.LReLU3_2(self.conv3_2(x)))\n",
        "        x = self.max_pool3(conv3)\n",
        "\n",
        "        ########## Starts: Bottom of the U-NET ##########\n",
        "        x_1 = self.bn4_11(self.LReLU4_11(self.conv4_11(x)))\n",
        "        x_2 = self.bn4_12(self.LReLU4_12(self.conv4_12(x)))\n",
        "        x_3 = self.bn4_13(self.LReLU4_13(self.conv4_13(x)))\n",
        "        x_4 = self.bn4_14(self.LReLU4_14(self.conv4_14(x)))\n",
        "        x = torch.cat([x_1,x_2,x_3,x_4], dim=1)\n",
        "        x = self.attention_4(x, input) if self.self_attention else x\n",
        "        conv6 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
        "\n",
        "        # uncomment this block for further downsampling\n",
        "        '''\n",
        "        x = self.bn4_1(self.LReLU4_1(self.conv4_1(x)))\n",
        "        conv4 = self.bn4_2(self.LReLU4_2(self.conv4_2(x)))\n",
        "        x = self.max_pool4(conv4)\n",
        "\n",
        "        x = self.bn5_1(self.LReLU5_1(self.conv5_1(x)))\n",
        "        #x = x*attention_map5 if self.self_attention else x\n",
        "        x = self.attention_5(x) if self.self_attention else x\n",
        "        conv5 = self.bn5_2(self.LReLU5_2(self.conv5_2(x)))\n",
        "\n",
        "        conv5 = F_upsample(conv5, scale_factor=2, mode='bilinear')\n",
        "        #conv4 = conv4*attention_map4 if self.self_attention else conv4\n",
        "        conv4 = self.attention_4(conv4) if self.self_attention else conv4\n",
        "        up6 = torch.cat([self.deconv5(conv5), conv4], 1)\n",
        "        x = self.bn6_1(self.LReLU6_1(self.conv6_1(up6)))\n",
        "        conv6 = self.bn6_2(self.LReLU6_2(self.conv6_2(x)))\n",
        "        '''\n",
        "        ########### Ends: Bottom of the U-NET ##########\n",
        "\n",
        "        conv6 = F_upsample(conv6, scale_factor=2, mode='bilinear')\n",
        "        conv3 = self.attention_3(conv3, input) if self.self_attention else conv3\n",
        "        up7 = torch.cat([self.deconv6(conv6), conv3], 1)\n",
        "        x = self.bn7_1(self.LReLU7_1(self.conv7_1(up7)))\n",
        "        conv7 = self.bn7_2(self.LReLU7_2(self.conv7_2(x)))\n",
        "\n",
        "        conv7 = F_upsample(conv7, scale_factor=2, mode='bilinear')\n",
        "        conv2 = self.attention_2(conv2, input) if self.self_attention else conv2\n",
        "        up8 = torch.cat([self.deconv7(conv7), conv2], 1)\n",
        "        x = self.bn8_1(self.LReLU8_1(self.conv8_1(up8)))\n",
        "        conv8 = self.bn8_2(self.LReLU8_2(self.conv8_2(x)))\n",
        "\n",
        "        conv8 = F_upsample(conv8, scale_factor=2, mode='bilinear')\n",
        "        conv1 = self.attention_1(conv1, input) if self.self_attention else conv1\n",
        "        up9 = torch.cat([self.deconv8(conv8), conv1], 1)\n",
        "        x = self.bn9_1(self.LReLU9_1(self.conv9_1(up9)))\n",
        "        conv9 = self.LReLU9_2(self.conv9_2(x))\n",
        "\n",
        "        latent = self.conv10(conv9)\n",
        "        latent = self.attention_out(latent, input) if self.self_attention else latent\n",
        "\n",
        "        if self.skip:\n",
        "            if self.normalize:\n",
        "                min_latent = torch.amin(latent, dim=(0,2,3), keepdim=True)\n",
        "                max_latent = torch.amax(latent, dim=(0,2,3), keepdim=True)\n",
        "                latent = (latent - min_latent) / (max_latent - min_latent)\n",
        "\n",
        "            output = latent + self.skip * input\n",
        "        else:\n",
        "            output = latent\n",
        "\n",
        "        if self.use_tanh:\n",
        "            output = self.final_tanh(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8Ggg5h0p2GV",
        "outputId": "1086854e-ca5f-4b85-a284-847c8a2ad338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 7\n",
        "norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "\n",
        "det_model=retinanet_resnet50_fpn(pretrained=True)\n",
        "in_features=det_model.head.classification_head.conv[0].out_channels\n",
        "det_model.head.classification_head=torchvision.models.detection.retinanet.RetinaNetClassificationHead(\n",
        "   in_channels=in_features,\n",
        "    num_anchors=det_model.head.classification_head.num_anchors,\n",
        "    num_classes=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KVSc7NFpKMYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad95c43f-f90d-4a39-d35a-2fb6595860ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.UnetGeneratorBilinear'> successfully loaded generator\n",
            "<class 'torchvision.models.detection.retinanet.RetinaNet'> successfully loaded detector\n"
          ]
        }
      ],
      "source": [
        "# Add Generator Model path here\n",
        "\n",
        "# gen_model_path = \"../Models/best_gan_model.pt\"\n",
        "ggen_model_path = \"drive/MyDrive/Models/best_gan_model.pt\"\n",
        "\n",
        "# Add Detector Model path here\n",
        "\n",
        "# det_model_path = \"../Models/best_detector_model.pt\"\n",
        "gdet_model_path = 'drive/MyDrive/Models/best_detector_model.pt'\n",
        "\n",
        "gen_model = UnetGeneratorBilinear(norm_layer=norm_layer)\n",
        "\n",
        "# gen_model_state_dict = torch.load(gen_model_path, map_location=torch.device('cpu'))\n",
        "# det_model_state_dict = torch.load(det_model_path, map_location=torch.device('cpu'))\n",
        "gen_model_state_dict = torch.load(ggen_model_path)\n",
        "det_model_state_dict = torch.load(gdet_model_path)\n",
        "\n",
        "\n",
        "gen_model.load_state_dict(gen_model_state_dict)\n",
        "det_model.load_state_dict(det_model_state_dict)\n",
        "\n",
        "gen_model.eval()\n",
        "det_model.eval()\n",
        "\n",
        "print(type(gen_model), \"successfully loaded generator\")\n",
        "print(type(det_model), \"successfully loaded detector\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cZLlRjMTp2GW"
      },
      "outputs": [],
      "source": [
        "def load_exr(filename):\n",
        "    \"\"\"Load an EXR file and return as a NumPy array.\"\"\"\n",
        "    file = OpenEXR.InputFile(filename)\n",
        "    dw = file.header()['dataWindow']\n",
        "    size = (dw.max.x - dw.min.x + 1, dw.max.y - dw.min.y + 1)\n",
        "\n",
        "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
        "    channels = ['R', 'G', 'B']\n",
        "\n",
        "    rgb = [np.frombuffer(file.channel(c, pt), dtype=np.float32) for c in channels]\n",
        "    rgb = [np.reshape(c, (size[1], size[0])) for c in rgb]\n",
        "\n",
        "    image = np.stack(rgb, axis=-1)\n",
        "    # image = image.resize((1080,1920), Image.LANCZOS)\n",
        "    return image\n",
        "\n",
        "def hdr_normalize(img):\n",
        "    hdr_max=65830.18848\n",
        "    hdr_min=-326.18848\n",
        "    real_A = F_normalize(img,\n",
        "                        [hdr_min, hdr_min, hdr_min],\n",
        "                        [hdr_max, hdr_max, hdr_max])\n",
        "    return real_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA8nE94kp2GX",
        "outputId": "6cca90a1-c9b8-4713-c5db-113ebb31b36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.0002e-04, 1.0002e-04, 1.1249e-01,  ..., 1.4294e-01,\n",
            "          1.4294e-01, 1.4294e-01],\n",
            "         [1.0002e-04, 1.0002e-04, 1.4294e-01,  ..., 1.4294e-01,\n",
            "          1.4294e-01, 1.4294e-01],\n",
            "         [1.0002e-04, 1.0002e-04, 1.1249e-01,  ..., 1.4294e-01,\n",
            "          1.4294e-01, 1.4294e-01],\n",
            "         ...,\n",
            "         [5.1123e-01, 5.1172e-01, 5.1172e-01,  ..., 1.7655e-04,\n",
            "          1.7655e-04, 1.7655e-04],\n",
            "         [3.8428e-01, 3.8574e-01, 3.8574e-01,  ..., 1.7655e-04,\n",
            "          1.0002e-04, 1.0002e-04],\n",
            "         [5.0977e-01, 5.0977e-01, 5.1172e-01,  ..., 1.1078e-01,\n",
            "          1.4294e-01, 1.4294e-01]],\n",
            "\n",
            "        [[5.2368e-02, 1.4404e-01, 1.4429e-01,  ..., 1.4185e-01,\n",
            "          1.4185e-01, 1.4185e-01],\n",
            "         [1.4404e-01, 1.4404e-01, 1.4185e-01,  ..., 1.4185e-01,\n",
            "          1.4185e-01, 1.4185e-01],\n",
            "         [1.4404e-01, 1.4404e-01, 1.4429e-01,  ..., 1.4185e-01,\n",
            "          1.4185e-01, 1.4185e-01],\n",
            "         ...,\n",
            "         [5.0684e-01, 6.3525e-01, 6.3525e-01,  ..., 1.5342e-04,\n",
            "          1.5342e-04, 1.5342e-04],\n",
            "         [6.3721e-01, 6.3574e-01, 6.3574e-01,  ..., 1.5342e-04,\n",
            "          1.4404e-01, 1.4404e-01],\n",
            "         [6.3525e-01, 6.3525e-01, 6.3525e-01,  ..., 1.0002e-04,\n",
            "          1.4185e-01, 1.4185e-01]],\n",
            "\n",
            "        [[1.0002e-04, 1.0002e-04, 1.0002e-04,  ..., 1.6809e-01,\n",
            "          1.6809e-01, 1.6809e-01],\n",
            "         [1.0002e-04, 1.0002e-04, 1.6809e-01,  ..., 1.6809e-01,\n",
            "          1.6809e-01, 1.6809e-01],\n",
            "         [1.0002e-04, 1.0002e-04, 1.0002e-04,  ..., 1.6809e-01,\n",
            "          1.6809e-01, 1.6809e-01],\n",
            "         ...,\n",
            "         [4.5386e-01, 4.5215e-01, 4.5215e-01,  ..., 1.6582e-04,\n",
            "          1.6582e-04, 1.6582e-04],\n",
            "         [3.0444e-01, 4.5288e-01, 6.0059e-01,  ..., 1.6582e-04,\n",
            "          1.0002e-04, 1.0002e-04],\n",
            "         [5.9863e-01, 5.9863e-01, 4.5215e-01,  ..., 1.6296e-01,\n",
            "          1.6809e-01, 1.6809e-01]]])\n",
            "torch.Size([1, 3, 1080, 1920])\n",
            "tensor([[[[0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          ...,\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]],\n",
            "\n",
            "         [[0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          ...,\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]],\n",
            "\n",
            "         [[0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          ...,\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
            "          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]]]])\n",
            "tensor(0.0050) tensor(0.0001)\n",
            "tensor(0.0088) tensor(255.)\n"
          ]
        }
      ],
      "source": [
        "exr_path = \"drive/MyDrive/Test Images/hdr_00348.exr\"\n",
        "\n",
        "exr_image = load_exr(exr_path)\n",
        "exr_image = torch.tensor(exr_image).permute(2,0,1)\n",
        "\n",
        "transform_img = transforms.Resize((1080,1920))\n",
        "\n",
        "exr_image = transform_img(exr_image)\n",
        "\n",
        "print(exr_image)\n",
        "\n",
        "norm_exr_img = hdr_normalize(exr_image)\n",
        "norm_exr_img = norm_exr_img.unsqueeze(0)\n",
        "print(norm_exr_img.shape)\n",
        "\n",
        "print(norm_exr_img)\n",
        "\n",
        "print(torch.min(norm_exr_img), torch.min(exr_image))\n",
        "print(torch.max(norm_exr_img), torch.max(exr_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbT5quZUp2GX",
        "outputId": "5de5f882-1d27-4ebc-8e1f-ccb3a5a562b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 1080, 1920])\n",
            "[{'boxes': tensor([[ 1.7013,  1.3144,  1.9755,  1.6812],\n",
            "        [ 0.0000,  1.2694,  0.2358,  1.6802],\n",
            "        [ 0.0000,  1.2694,  0.2358,  1.6802],\n",
            "        [ 0.2444,  0.3373,  0.5347,  0.7034],\n",
            "        [ 0.1511,  0.2567,  0.4262,  0.6656],\n",
            "        [ 0.1214,  0.4943,  0.4032,  0.8926],\n",
            "        [ 1.6137,  0.0571,  1.9030,  0.4501],\n",
            "        [ 0.5087,  0.5886,  0.8019,  0.9526],\n",
            "        [ 1.6137,  0.0571,  1.9030,  0.4501],\n",
            "        [ 0.1511,  0.2567,  0.4262,  0.6656],\n",
            "        [ 0.6851,  0.2137,  0.9675,  0.6433],\n",
            "        [ 0.2354,  0.5353,  0.5173,  0.9288],\n",
            "        [ 0.2354,  0.5353,  0.5173,  0.9288],\n",
            "        [ 0.6851,  0.2137,  0.9675,  0.6433],\n",
            "        [ 1.9078,  1.0996,  2.1827,  1.4594],\n",
            "        [ 1.7013,  1.3144,  1.9755,  1.6812],\n",
            "        [ 0.3853,  0.0000,  0.6699,  0.2839],\n",
            "        [ 0.3853,  0.0000,  0.6699,  0.2839],\n",
            "        [ 0.1214,  0.4943,  0.4032,  0.8926],\n",
            "        [ 0.2444,  0.3373,  0.5347,  0.7034],\n",
            "        [ 0.5087,  0.5886,  0.8019,  0.9526],\n",
            "        [ 1.9078,  1.0996,  2.1827,  1.4594],\n",
            "        [ 0.1511,  0.2567,  0.4262,  0.6656],\n",
            "        [ 0.6851,  0.2137,  0.9675,  0.6433],\n",
            "        [ 0.2354,  0.5353,  0.5173,  0.9288],\n",
            "        [ 1.6137,  0.0571,  1.9030,  0.4501],\n",
            "        [ 0.1214, 12.0297,  0.4032, 12.4280],\n",
            "        [ 0.3853,  0.0000,  0.6699,  0.2839],\n",
            "        [ 0.0000,  1.2694,  0.2358,  1.6802],\n",
            "        [ 0.0000, 13.0396,  0.0000, 13.4691],\n",
            "        [ 0.2444, 11.8727,  0.5347, 12.2388],\n",
            "        [ 0.0000, 13.0396,  0.0000, 13.4691],\n",
            "        [ 0.1511,  0.2567,  0.4262,  0.6656],\n",
            "        [ 0.1214, 12.0297,  0.4032, 12.4280],\n",
            "        [ 0.6851,  0.2137,  0.9675,  0.6433],\n",
            "        [ 0.6851,  0.2137,  0.9675,  0.6433],\n",
            "        [ 0.3853,  0.0000,  0.6699,  0.2839],\n",
            "        [ 0.1511,  0.2567,  0.4262,  0.6656],\n",
            "        [ 0.1214,  0.4943,  0.4032,  0.8926],\n",
            "        [ 1.6137,  0.0571,  1.9030,  0.4501],\n",
            "        [ 0.0000,  1.2694,  0.2358,  1.6802],\n",
            "        [13.1252,  0.1257, 13.4187,  0.5095],\n",
            "        [ 0.2354,  0.5353,  0.5173,  0.9288],\n",
            "        [ 1.7013,  1.3144,  1.9755,  1.6812],\n",
            "        [ 1.6137,  0.0571,  1.9030,  0.4501],\n",
            "        [ 0.3853,  0.0000,  0.6699,  0.2839],\n",
            "        [13.1252,  0.1257, 13.4187,  0.5095],\n",
            "        [ 0.5087,  0.5886,  0.8019,  0.9526],\n",
            "        [ 0.0000,  1.2694,  0.2358,  1.6802],\n",
            "        [ 0.2354,  0.5353,  0.5173,  0.9288],\n",
            "        [ 0.0000,  4.8730,  0.0000,  5.3661]], grad_fn=<StackBackward0>), 'scores': tensor([0.4149, 0.4083, 0.4008, 0.4007, 0.3969, 0.3938, 0.3795, 0.3793, 0.3781,\n",
            "        0.3776, 0.3773, 0.3740, 0.3690, 0.3688, 0.3650, 0.3531, 0.3463, 0.3402,\n",
            "        0.3358, 0.3310, 0.3240, 0.2944, 0.1435, 0.1368, 0.1309, 0.1272, 0.1249,\n",
            "        0.1180, 0.1121, 0.1118, 0.1040, 0.1001, 0.0955, 0.0928, 0.0920, 0.0875,\n",
            "        0.0833, 0.0809, 0.0796, 0.0789, 0.0789, 0.0780, 0.0749, 0.0743, 0.0719,\n",
            "        0.0676, 0.0659, 0.0612, 0.0558, 0.0521, 0.0503],\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 4, 4,\n",
            "        4, 4, 1, 4, 4, 1, 1, 0, 3, 0, 3, 5, 3, 5, 4, 3, 3, 1, 3, 4, 5, 5, 0, 4,\n",
            "        5, 5, 0])}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "save_path = \"drive/MyDrive/Generated Images/gen.png\"\n",
        "\n",
        "gen_img = gen_model(norm_exr_img)\n",
        "print(gen_img.shape)\n",
        "det_out = det_model(gen_img)\n",
        "print(det_out)\n",
        "img = gen_img.detach().cpu().numpy()*255.0\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "# cv2.imwrite(save_path, img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imwrite(save_path, img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSRA6dDpr6di",
        "outputId": "3fadc02d-6c9d-417c-801d-6a65bd5b9447"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWR10YHgtGMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}