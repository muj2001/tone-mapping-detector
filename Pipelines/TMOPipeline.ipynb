{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python-headless\n",
        "# !pip install imageio\n",
        "# !pip install OpenEXR\n",
        "# !pip install Imath\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
        "\n",
        "import os\n",
        "print(os.environ.get('OPENCV_IO_ENABLE_OPENEXR'))\n",
        "\n",
        "import cv2\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# !pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "import OpenEXR\n",
        "import Imath\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "SZXN0o2DXDOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034cfe52-3e51-4fa6-c310-ed81a8a21db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless -y\n",
        "!pip uninstall opencv-python -y\n",
        "!apt update\n",
        "!apt install python3-opencv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DysHtZYxT2v1",
        "outputId": "e2d79c8d-6973-4292-d773-6be524d62b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.9.0.80\n",
            "Uninstalling opencv-python-headless-4.9.0.80:\n",
            "  Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "Found existing installation: opencv-python 4.8.0.76\n",
            "Uninstalling opencv-python-4.8.0.76:\n",
            "  Successfully uninstalled opencv-python-4.8.0.76\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,081 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,104 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,641 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,920 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,358 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 8,337 kB in 1s (5,899 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-pytest\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 5,272 kB of archives.\n",
            "After this operation, 27.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-opencv amd64 4.5.4+dfsg-9ubuntu4+jammy0 [1,805 kB]\n",
            "Fetched 5,272 kB in 3s (1,530 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-opencv:amd64.\n",
            "Preparing to unpack .../python3-opencv_4.5.4+dfsg-9ubuntu4+jammy0_amd64.deb ...\n",
            "Unpacking python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-opencv:amd64 (4.5.4+dfsg-9ubuntu4+jammy0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "print(cv2.__version__)\n",
        "print(cv2.getBuildInformation())\n",
        "\n",
        "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NCkjOaST9sC",
        "outputId": "71c63f26-c994-4c69-d35e-e5d1f90ace13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.8.0\n",
            "\n",
            "General configuration for OpenCV 4.8.0 =====================================\n",
            "  Version control:               4.8.0-dirty\n",
            "\n",
            "  Extra modules:\n",
            "    Location (extra):            /io/opencv_contrib/modules\n",
            "    Version control (extra):     4.8.0\n",
            "\n",
            "  Platform:\n",
            "    Timestamp:                   2023-08-09T11:58:06Z\n",
            "    Host:                        Linux 5.15.0-1042-azure x86_64\n",
            "    CMake:                       3.27.1\n",
            "    CMake generator:             Unix Makefiles\n",
            "    CMake build tool:            /bin/gmake\n",
            "    Configuration:               Release\n",
            "\n",
            "  CPU/HW features:\n",
            "    Baseline:                    SSE SSE2 SSE3\n",
            "      requested:                 SSE3\n",
            "    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX\n",
            "      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX\n",
            "      SSE4_1 (16 files):         + SSSE3 SSE4_1\n",
            "      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2\n",
            "      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX\n",
            "      AVX (7 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX\n",
            "      AVX2 (35 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2\n",
            "      AVX512_SKX (5 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX\n",
            "\n",
            "  C/C++:\n",
            "    Built as dynamic libs?:      NO\n",
            "    C++ standard:                11\n",
            "    C++ Compiler:                /opt/rh/devtoolset-10/root/usr/bin/c++  (ver 10.2.1)\n",
            "    C++ flags (Release):         -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n",
            "    C++ flags (Debug):           -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n",
            "    C Compiler:                  /opt/rh/devtoolset-10/root/usr/bin/cc\n",
            "    C flags (Release):           -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG\n",
            "    C flags (Debug):             -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG\n",
            "    Linker flags (Release):      -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a -L/ffmpeg_build/lib  -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
            "    Linker flags (Debug):        -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a -L/ffmpeg_build/lib  -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
            "    ccache:                      YES\n",
            "    Precompiled headers:         NO\n",
            "    Extra dependencies:          /lib64/libopenblas.so Qt5::Test Qt5::Concurrent /usr/local/lib/libpng.so /lib64/libz.so Qt5::Core Qt5::Gui Qt5::Widgets Iconv::Iconv dl m pthread rt\n",
            "    3rdparty dependencies:       libprotobuf ade ittnotify libjpeg-turbo libwebp libtiff libopenjp2 IlmImf quirc ippiw ippicv\n",
            "\n",
            "  OpenCV modules:\n",
            "    To be built:                 aruco bgsegm bioinspired calib3d ccalib core cvv datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto\n",
            "    Disabled:                    world\n",
            "    Disabled by dependency:      -\n",
            "    Unavailable:                 alphamat cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev freetype hdf java julia matlab ovis python2 sfm ts viz\n",
            "    Applications:                -\n",
            "    Documentation:               NO\n",
            "    Non-free algorithms:         NO\n",
            "\n",
            "  GUI:                           QT5\n",
            "    QT:                          YES (ver 5.15.0 )\n",
            "      QT OpenGL support:         NO\n",
            "    GTK+:                        NO\n",
            "    VTK support:                 NO\n",
            "\n",
            "  Media I/O: \n",
            "    ZLib:                        /lib64/libz.so (ver 1.2.7)\n",
            "    JPEG:                        libjpeg-turbo (ver 2.1.3-62)\n",
            "    WEBP:                        build (ver encoder: 0x020f)\n",
            "    PNG:                         /usr/local/lib/libpng.so (ver 1.6.40)\n",
            "    TIFF:                        build (ver 42 - 4.2.0)\n",
            "    JPEG 2000:                   build (ver 2.5.0)\n",
            "    OpenEXR:                     build (ver 2.3.0)\n",
            "    HDR:                         YES\n",
            "    SUNRASTER:                   YES\n",
            "    PXM:                         YES\n",
            "    PFM:                         YES\n",
            "\n",
            "  Video I/O:\n",
            "    DC1394:                      NO\n",
            "    FFMPEG:                      YES\n",
            "      avcodec:                   YES (59.37.100)\n",
            "      avformat:                  YES (59.27.100)\n",
            "      avutil:                    YES (57.28.100)\n",
            "      swscale:                   YES (6.7.100)\n",
            "      avresample:                NO\n",
            "    GStreamer:                   NO\n",
            "    v4l/v4l2:                    YES (linux/videodev2.h)\n",
            "\n",
            "  Parallel framework:            pthreads\n",
            "\n",
            "  Trace:                         YES (with Intel ITT)\n",
            "\n",
            "  Other third-party libraries:\n",
            "    Intel IPP:                   2021.8 [2021.8.0]\n",
            "           at:                   /io/_skbuild/linux-x86_64-3.7/cmake-build/3rdparty/ippicv/ippicv_lnx/icv\n",
            "    Intel IPP IW:                sources (2021.8.0)\n",
            "              at:                /io/_skbuild/linux-x86_64-3.7/cmake-build/3rdparty/ippicv/ippicv_lnx/iw\n",
            "    VA:                          NO\n",
            "    Lapack:                      YES (/lib64/libopenblas.so)\n",
            "    Eigen:                       NO\n",
            "    Custom HAL:                  NO\n",
            "    Protobuf:                    build (3.19.1)\n",
            "    Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
            "\n",
            "  OpenCL:                        YES (no extra features)\n",
            "    Include path:                /io/opencv/3rdparty/include/opencl/1.2\n",
            "    Link libraries:              Dynamic load\n",
            "\n",
            "  Python 3:\n",
            "    Interpreter:                 /opt/python/cp37-cp37m/bin/python3.7 (ver 3.7.17)\n",
            "    Libraries:                   libpython3.7m.a (ver 3.7.17)\n",
            "    numpy:                       /home/ci/.local/lib/python3.7/site-packages/numpy/core/include (ver 1.17.0)\n",
            "    install path:                python/cv2/python-3\n",
            "\n",
            "  Python (for build):            /opt/python/cp37-cp37m/bin/python3.7\n",
            "\n",
            "  Java:                          \n",
            "    ant:                         NO\n",
            "    Java:                        NO\n",
            "    JNI:                         NO\n",
            "    Java wrappers:               NO\n",
            "    Java tests:                  NO\n",
            "\n",
            "  Install to:                    /io/_skbuild/linux-x86_64-3.7/cmake-install\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------- LOAD DATASET HERE ----------------------------------\n",
        "# !ls '/content/drive/MyDrive/hdr_dataset/hdr'\n",
        "hdr_file_pattern = '/content/drive/MyDrive/hdr_dataset/hdr/*.exr'\n",
        "# MyDrive/DIP Project/HDR Dataset 1'\n",
        "# Loading one image:\n",
        "hdr_images = []\n",
        "\n",
        "for hdr_file_path in glob.glob(hdr_file_pattern):\n",
        "\n",
        "    # Open the OpenEXR file\n",
        "    hdr_file = OpenEXR.InputFile(hdr_file_path)\n",
        "\n",
        "    # Get the header information\n",
        "    header = hdr_file.header()\n",
        "\n",
        "    # Get the image dimensions from the header\n",
        "    dw = header['dataWindow']\n",
        "    width = dw.max.x - dw.min.x + 1\n",
        "    height = dw.max.y - dw.min.y + 1\n",
        "\n",
        "    # Read the image data\n",
        "    # Assuming the image has RGB channels, change it according to your case\n",
        "    channel_names = ['R', 'G', 'B']  # Change this if your image has different channels\n",
        "    for c in channel_names:\n",
        "        print(c)\n",
        "        # print(hdr_file.channel(c))\n",
        "        print(type(hdr_file.channel(c)))\n",
        "        # print(hdr_file.channel(c).shape\n",
        "    data = [np.frombuffer(hdr_file.channel(c), dtype=np.float32) for c in channel_names]\n",
        "    for d in data:\n",
        "        print(d.shape)\n",
        "        d = d.reshape((height, width))\n",
        "    image_data = np.stack(data, axis=-1)\n",
        "    break\n",
        "# Now you have the image data in NumPy array format\n",
        "print(\"Image dimensions:\", image_data.shape)"
      ],
      "metadata": {
        "id": "UpidGcQW-uIk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "34fc9557-44b0-4537-8f40-bdcc206655d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R\n",
            "<class 'bytes'>\n",
            "G\n",
            "<class 'bytes'>\n",
            "B\n",
            "<class 'bytes'>\n",
            "(1036800,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 1036800 into shape (1080,1920)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-2594de40d2d7>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1036800 into shape (1080,1920)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IGNORE THIS BLOCK AT THE MOMENT --------------------\n",
        "\n",
        "def discriminator_loss(D, real_images, fake_images):\n",
        "  real_loss = F.mse_loss(D(real_images), torch.ones_like(D(real_images)))\n",
        "  fake_loss = F.mse_loss(D(fake_images), torch.zeros_like(D(fake_images)))\n",
        "  return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(G, fake_images):\n",
        "  return F.mse_loss(G(fake_images), torch.ones_like(G(fake_images)))\n",
        "\n",
        "# Optional: L1 Content Loss to enforce similarity between generated and real LDR images\n",
        "def l1_content_loss(fake_images, real_images):\n",
        "    return torch.mean(torch.abs(fake_images - real_images))\n",
        "\n",
        "\n",
        "# def detector_loss():\n",
        "#   # TBD\n",
        "#   pass"
      ],
      "metadata": {
        "id": "Hu82CHj2WGmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- BASIC GAN LOSSES -------------------------\n",
        "\n",
        "def generator_adversarial_loss(D, fake_images):\n",
        "    return torch.mean((D(fake_images) - 1) ** 2)\n",
        "\n",
        "def discriminator_adverserial_loss(D, real_images, fake_images):\n",
        "    real_loss = torch.mean((D(real_images) - 1) ** 2)\n",
        "    fake_loss = torch.mean(D(fake_images) ** 2)\n",
        "    return (real_loss + fake_loss) / 2"
      ],
      "metadata": {
        "id": "iXqnnyIMXTWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- GENERATOR ARCHITECTURE -------------------------\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.ins = nn.InstanceNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      x = self.ins(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "class AttentionModule(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(AttentionModule, self).__init__()\n",
        "    self.attention_score = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "      score = self.attention_score(x)\n",
        "      score = self.sigmoid(score)\n",
        "      attention_map = torch.mul(score, x)\n",
        "      return attention_map\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = ConvBlock(in_channels, 32, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv2 = ConvBlock(32, 64, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv3 = ConvBlock(64, 128, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv4 = ConvBlock(512, 128, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv5 = ConvBlock(128, 64, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv6 = ConvBlock(64, 3, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.attention1 = AttentionModule(32, 32)\n",
        "        self.attention2 = AttentionModule(64, 64)\n",
        "        self.attention3 = AttentionModule(512, 512)\n",
        "\n",
        "        self.k3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.k5 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2)\n",
        "        self.k7 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3)\n",
        "        self.k9 = nn.Conv2d(128, 128, kernel_size=9, stride=1, padding=4)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest') # TESTING\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        att_1 = self.attention1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(x)\n",
        "        att_2 = self.attention2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x_1 = self.k3(x)\n",
        "        x_2 = self.k5(x)\n",
        "        x_3 = self.k7(x)\n",
        "        x_4 = self.k9(x)\n",
        "        x = torch.cat((x_1, x_2, x_3, x_4), dim=1) # TESTING\n",
        "        att_3 = self.attention3(x)\n",
        "        x = self.upsample(att_3) # CONTINUE CODING HERE\n",
        "        x = self.conv4(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.conv6(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "6fq4dVtTiD6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- DISCRIMINATOR ARCHITECTURE -------------------------\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        # Block 1 Input -> Channels x H x W\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Block 2 Input -> 64 * H/2 * W/2\n",
        "        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n",
        "        nn.InstanceNorm2d(512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.model(x)"
      ],
      "metadata": {
        "id": "HVTIYlw2MXpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------- PATCH DISCRIMINATOR -------------------\n",
        "\n",
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(PatchDiscriminator, self).__init__()\n",
        "\n",
        "        # Define layers\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "        # Instance normalization\n",
        "        self.instance_norm = nn.InstanceNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through convolutional layers\n",
        "        x = nn.LeakyReLU(0.2)(self.conv1(x))\n",
        "        x = nn.LeakyReLU(0.2)(self.instance_norm(self.conv2(x)))\n",
        "        x = nn.LeakyReLU(0.2)(self.instance_norm(self.conv3(x)))\n",
        "        x = nn.LeakyReLU(0.2)(self.instance_norm(self.conv4(x)))\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "slrlvWvZ8AmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256\n",
        "W = 256\n",
        "batch_size = 1\n",
        "in_channels =3\n",
        "# Testing\n",
        "\n",
        "gen_model = Generator(in_channels=3)\n",
        "print(summary(gen_model, input_size=(batch_size, in_channels, H, W)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4YyqCw3x29C",
        "outputId": "511c1d5d-bc80-4904-f866-be8417877c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Generator                                [1, 3, 256, 256]          --\n",
            "├─ConvBlock: 1-1                         [1, 32, 256, 256]         --\n",
            "│    └─Conv2d: 2-1                       [1, 32, 256, 256]         128\n",
            "│    └─InstanceNorm2d: 2-2               [1, 32, 256, 256]         --\n",
            "│    └─ReLU: 2-3                         [1, 32, 256, 256]         --\n",
            "├─MaxPool2d: 1-2                         [1, 32, 128, 128]         --\n",
            "├─AttentionModule: 1-3                   [1, 32, 128, 128]         --\n",
            "│    └─Conv2d: 2-4                       [1, 32, 128, 128]         1,056\n",
            "│    └─Sigmoid: 2-5                      [1, 32, 128, 128]         --\n",
            "├─ConvBlock: 1-4                         [1, 64, 128, 128]         --\n",
            "│    └─Conv2d: 2-6                       [1, 64, 128, 128]         2,112\n",
            "│    └─InstanceNorm2d: 2-7               [1, 64, 128, 128]         --\n",
            "│    └─ReLU: 2-8                         [1, 64, 128, 128]         --\n",
            "├─MaxPool2d: 1-5                         [1, 64, 64, 64]           --\n",
            "├─AttentionModule: 1-6                   [1, 64, 64, 64]           --\n",
            "│    └─Conv2d: 2-9                       [1, 64, 64, 64]           4,160\n",
            "│    └─Sigmoid: 2-10                     [1, 64, 64, 64]           --\n",
            "├─ConvBlock: 1-7                         [1, 128, 64, 64]          --\n",
            "│    └─Conv2d: 2-11                      [1, 128, 64, 64]          8,320\n",
            "│    └─InstanceNorm2d: 2-12              [1, 128, 64, 64]          --\n",
            "│    └─ReLU: 2-13                        [1, 128, 64, 64]          --\n",
            "├─MaxPool2d: 1-8                         [1, 128, 32, 32]          --\n",
            "├─Conv2d: 1-9                            [1, 128, 32, 32]          147,584\n",
            "├─Conv2d: 1-10                           [1, 128, 32, 32]          409,728\n",
            "├─Conv2d: 1-11                           [1, 128, 32, 32]          802,944\n",
            "├─Conv2d: 1-12                           [1, 128, 32, 32]          1,327,232\n",
            "├─AttentionModule: 1-13                  [1, 512, 32, 32]          --\n",
            "│    └─Conv2d: 2-14                      [1, 512, 32, 32]          262,656\n",
            "│    └─Sigmoid: 2-15                     [1, 512, 32, 32]          --\n",
            "├─Upsample: 1-14                         [1, 512, 64, 64]          --\n",
            "├─ConvBlock: 1-15                        [1, 128, 64, 64]          --\n",
            "│    └─Conv2d: 2-16                      [1, 128, 64, 64]          65,664\n",
            "│    └─InstanceNorm2d: 2-17              [1, 128, 64, 64]          --\n",
            "│    └─ReLU: 2-18                        [1, 128, 64, 64]          --\n",
            "├─Upsample: 1-16                         [1, 128, 128, 128]        --\n",
            "├─ConvBlock: 1-17                        [1, 64, 128, 128]         --\n",
            "│    └─Conv2d: 2-19                      [1, 64, 128, 128]         8,256\n",
            "│    └─InstanceNorm2d: 2-20              [1, 64, 128, 128]         --\n",
            "│    └─ReLU: 2-21                        [1, 64, 128, 128]         --\n",
            "├─Upsample: 1-18                         [1, 64, 256, 256]         --\n",
            "├─ConvBlock: 1-19                        [1, 3, 256, 256]          --\n",
            "│    └─Conv2d: 2-22                      [1, 3, 256, 256]          195\n",
            "│    └─InstanceNorm2d: 2-23              [1, 3, 256, 256]          --\n",
            "│    └─ReLU: 2-24                        [1, 3, 256, 256]          --\n",
            "==========================================================================================\n",
            "Total params: 3,040,035\n",
            "Trainable params: 3,040,035\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 3.55\n",
            "==========================================================================================\n",
            "Input size (MB): 0.79\n",
            "Forward/backward pass size (MB): 58.20\n",
            "Params size (MB): 12.16\n",
            "Estimated Total Size (MB): 71.14\n",
            "==========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_disc_model = PatchDiscriminator(in_channels=3)\n",
        "print(summary(patch_disc_model, input_size=(batch_size, in_channels, H, W)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk7dMYGl8twy",
        "outputId": "65d78ca7-01cf-4571-d705-d66ee0f4f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "PatchDiscriminator                       [1, 1, 30, 30]            --\n",
            "├─Conv2d: 1-1                            [1, 64, 128, 128]         3,136\n",
            "├─Conv2d: 1-2                            [1, 128, 64, 64]          131,200\n",
            "├─InstanceNorm2d: 1-3                    [1, 128, 64, 64]          --\n",
            "├─Conv2d: 1-4                            [1, 256, 32, 32]          524,544\n",
            "├─InstanceNorm2d: 1-5                    [1, 256, 32, 32]          --\n",
            "├─Conv2d: 1-6                            [1, 512, 31, 31]          2,097,664\n",
            "├─InstanceNorm2d: 1-7                    [1, 512, 31, 31]          --\n",
            "├─Conv2d: 1-8                            [1, 1, 30, 30]            8,193\n",
            "==========================================================================================\n",
            "Total params: 2,764,737\n",
            "Trainable params: 2,764,737\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 3.15\n",
            "==========================================================================================\n",
            "Input size (MB): 0.79\n",
            "Forward/backward pass size (MB): 18.62\n",
            "Params size (MB): 11.06\n",
            "Estimated Total Size (MB): 30.47\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
            "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_model = Discriminator(in_channels=3)\n",
        "print(summary(disc_model, input_size=(batch_size, in_channels, H, W)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq0Sv6g7y_6g",
        "outputId": "f12e0818-8795-4cc3-fa59-ae683451f159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Discriminator                            [1, 1, 30, 30]            --\n",
            "├─Sequential: 1-1                        [1, 1, 30, 30]            --\n",
            "│    └─Conv2d: 2-1                       [1, 64, 128, 128]         3,136\n",
            "│    └─LeakyReLU: 2-2                    [1, 64, 128, 128]         --\n",
            "│    └─Conv2d: 2-3                       [1, 128, 64, 64]          131,200\n",
            "│    └─InstanceNorm2d: 2-4               [1, 128, 64, 64]          --\n",
            "│    └─LeakyReLU: 2-5                    [1, 128, 64, 64]          --\n",
            "│    └─Conv2d: 2-6                       [1, 256, 32, 32]          524,544\n",
            "│    └─InstanceNorm2d: 2-7               [1, 256, 32, 32]          --\n",
            "│    └─LeakyReLU: 2-8                    [1, 256, 32, 32]          --\n",
            "│    └─Conv2d: 2-9                       [1, 512, 31, 31]          2,097,664\n",
            "│    └─InstanceNorm2d: 2-10              [1, 512, 31, 31]          --\n",
            "│    └─LeakyReLU: 2-11                   [1, 512, 31, 31]          --\n",
            "│    └─Conv2d: 2-12                      [1, 1, 30, 30]            8,193\n",
            "==========================================================================================\n",
            "Total params: 2,764,737\n",
            "Trainable params: 2,764,737\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 3.15\n",
            "==========================================================================================\n",
            "Input size (MB): 0.79\n",
            "Forward/backward pass size (MB): 18.62\n",
            "Params size (MB): 11.06\n",
            "Estimated Total Size (MB): 30.47\n",
            "==========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ TRAINING -------------------\n",
        "\n",
        "# Instantiate Generator and Discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        discriminator_optimizer.zero_grad()\n",
        "\n",
        "        # Train with real images\n",
        "        real_labels = torch.ones(batch_size, 1)\n",
        "        output = discriminator(real_images)\n",
        "        real_loss = criterion(output, real_labels)\n",
        "\n",
        "        # Train with fake images\n",
        "        fake_labels = torch.zeros(batch_size, 1)\n",
        "        # noise = torch.randn(batch_size, input_dim, 1, 1)\n",
        "        fake_images = generator(hdr_images) # NEED HDR IMAGES\n",
        "        output = discriminator(fake_images.detach())\n",
        "        fake_loss = criterion(output, fake_labels)\n",
        "\n",
        "        discriminator_loss = real_loss + fake_loss\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        # Train Generator\n",
        "        generator_optimizer.zero_grad()\n",
        "\n",
        "        # noise = torch.randn(batch_size, noise_dim, 1, 1)\n",
        "        fake_images = generator(hdr_images) # NEED HDR IMAGES\n",
        "        output = discriminator(fake_images)\n",
        "        generator_loss = criterion(output, real_labels)\n",
        "\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        # Print training losses\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], \"\n",
        "                  f\"Discriminator Loss: {discriminator_loss.item():.4f}, \"\n",
        "                  f\"Generator Loss: {generator_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "72JUp_D98_zK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}